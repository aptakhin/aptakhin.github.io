{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"unifex","text":"<p>A Python library for document text extraction with local and cloud OCR solutions.</p>"},{"location":"#overview","title":"Overview","text":"<p>unifex is built for tasks like fraud detection where precision matters. It provides a universal tool for both PDF and image processing with best-in-class OCR support through local engines and cloud services.</p>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>Multiple OCR Backends: Local (EasyOCR, Tesseract, PaddleOCR) and cloud (Azure Document Intelligence, Google Document AI)</li> <li>PDF Text Extraction: Native PDF text extraction using pypdfium2</li> <li>LLM Extraction: Extract structured data using GPT-4o, Claude, Gemini, or OpenAI-compatible APIs</li> <li>Parallel Extraction: Process multiple pages concurrently with thread or process executors</li> <li>Async Support: Native async/await API for integration with async applications</li> <li>Unified Extractors: Each OCR extractor auto-detects file type (PDF vs image) and handles conversion internally</li> <li>Pydantic Models: Type-safe document representation with pydantic v1/v2 compatibility</li> </ul>"},{"location":"#quick-example","title":"Quick Example","text":"<pre><code>from unifex import create_extractor, ExtractorType\n\n# PDF extraction (native text)\nwith create_extractor(\"document.pdf\", ExtractorType.PDF) as extractor:\n    result = extractor.extract()\n    print(f\"Extracted {len(result.document.pages)} pages\")\n</code></pre>"},{"location":"#alternatives","title":"Alternatives","text":"<p>For broader document processing, check out Docling and Kreuzberg.</p>"},{"location":"#license","title":"License","text":"<p>BSD 3-Clause License. See LICENSE for details.</p>"},{"location":"development/architecture/","title":"Architecture","text":""},{"location":"development/architecture/#project-structure","title":"Project Structure","text":"<pre><code>unifex/\n\u251c\u2500\u2500 cli.py              # Command-line interface\n\u251c\u2500\u2500 coordinates.py      # Coordinate unit conversions\n\u251c\u2500\u2500 models.py           # Core data models\n\u251c\u2500\u2500 text_factory.py     # Unified factory interface\n\u251c\u2500\u2500 base/               # Base classes and models\n\u2502   \u251c\u2500\u2500 base.py         # BaseExtractor class\n\u2502   \u251c\u2500\u2500 models.py       # Document, Page, TextBlock, etc.\n\u2502   \u2514\u2500\u2500 coordinates.py  # Coordinate conversion logic\n\u251c\u2500\u2500 pdf/                # PDF text extraction\n\u2502   \u251c\u2500\u2500 pdf.py          # PdfExtractor implementation\n\u2502   \u2514\u2500\u2500 character_mergers.py  # Text merging strategies\n\u251c\u2500\u2500 ocr/                # OCR extraction\n\u2502   \u251c\u2500\u2500 adapters/       # External API \u2192 internal models\n\u2502   \u2502   \u251c\u2500\u2500 azure_di.py\n\u2502   \u2502   \u251c\u2500\u2500 google_docai.py\n\u2502   \u2502   \u251c\u2500\u2500 easy_ocr.py\n\u2502   \u2502   \u251c\u2500\u2500 paddle_ocr.py\n\u2502   \u2502   \u2514\u2500\u2500 tesseract_ocr.py\n\u2502   \u2514\u2500\u2500 extractors/     # OCR extractor implementations\n\u2502       \u251c\u2500\u2500 azure_di.py\n\u2502       \u251c\u2500\u2500 google_docai.py\n\u2502       \u251c\u2500\u2500 easy_ocr.py\n\u2502       \u251c\u2500\u2500 paddle_ocr.py\n\u2502       \u2514\u2500\u2500 tesseract_ocr.py\n\u251c\u2500\u2500 llm/                # LLM-based extraction\n\u2502   \u251c\u2500\u2500 factory.py      # extract_structured functions\n\u2502   \u251c\u2500\u2500 models.py       # LLM-specific models\n\u2502   \u251c\u2500\u2500 adapters/\n\u2502   \u2502   \u2514\u2500\u2500 image_encoder.py\n\u2502   \u2514\u2500\u2500 extractors/\n\u2502       \u251c\u2500\u2500 anthropic.py\n\u2502       \u251c\u2500\u2500 openai.py\n\u2502       \u251c\u2500\u2500 azure_openai.py\n\u2502       \u2514\u2500\u2500 google.py\n\u2514\u2500\u2500 utils/              # Shared utilities\n    \u251c\u2500\u2500 geometry.py\n    \u2514\u2500\u2500 image_loader.py\n</code></pre>"},{"location":"development/architecture/#layered-architecture","title":"Layered Architecture","text":"<p>The project follows a layered architecture enforced by import-linter:</p> <pre><code>cli.py\n   \u2193\ntext_factory.py\n   \u2193\npdf/, ocr/, llm/\n   \u2193\nbase/\n</code></pre>"},{"location":"development/architecture/#rules","title":"Rules","text":"<ol> <li>OCR and LLM are independent - They don't import from each other</li> <li>Base has no upward dependencies - It doesn't import from pdf, ocr, llm, or cli</li> <li>OCR extractors are independent - Each OCR extractor is self-contained</li> </ol>"},{"location":"development/architecture/#adapter-pattern","title":"Adapter Pattern","text":"<p>Adapters transform external API responses to internal models:</p> <pre><code>External API Response \u2192 Adapter \u2192 Page/TextBlock\n</code></pre> <p>This keeps extractors clean and makes it easy to: - Add new OCR providers - Update when APIs change - Test transformations in isolation</p>"},{"location":"development/architecture/#extractor-interface","title":"Extractor Interface","text":"<p>All extractors implement <code>BaseExtractor</code>:</p> <pre><code>class BaseExtractor:\n    def extract(\n        self,\n        pages: Sequence[int] | None = None,\n        max_workers: int = 1,\n        executor: ExecutorType = ExecutorType.THREAD,\n        **kwargs,\n    ) -&gt; ExtractionResult: ...\n\n    async def extract_async(\n        self,\n        pages: Sequence[int] | None = None,\n        max_workers: int = 1,\n        **kwargs,\n    ) -&gt; ExtractionResult: ...\n\n    def extract_page(self, page: int, **kwargs) -&gt; PageExtractionResult: ...\n\n    def get_page_count(self) -&gt; int: ...\n\n    def close(self) -&gt; None: ...\n</code></pre>"},{"location":"development/architecture/#thread-safety","title":"Thread Safety","text":""},{"location":"development/architecture/#pdf-extractor","title":"PDF Extractor","text":"<p>The PDF extractor uses pypdfium2, which is not thread-safe. To enable parallel page extraction, <code>PdfExtractor</code> uses an internal <code>threading.Lock</code> per instance:</p> <pre><code>class PdfExtractor:\n    def __init__(self, ...):\n        self._lock = threading.Lock()\n\n    def extract_page(self, page: int, ...):\n        with self._lock:\n            pdf_page = self._pdf[page]\n            # ... extraction logic\n</code></pre> <p>This means:</p> <ul> <li>Thread executor works - Multiple threads can call <code>extract_page()</code> on the same extractor instance; the lock serializes PDF access</li> <li>Process executor duplicates - Each process gets its own <code>PdfExtractor</code> instance with its own PDF handle</li> <li>Single extractor, multiple threads - Safe due to internal locking</li> </ul>"},{"location":"development/architecture/#ocr-extractors","title":"OCR Extractors","text":"<p>OCR extractors have varying thread-safety characteristics:</p> Extractor Thread-Safe Notes EasyOCR Yes Model shared across threads Tesseract Yes Subprocess-based PaddleOCR Yes Model shared across threads Azure DI Yes HTTP client is thread-safe Google DocAI Yes gRPC client is thread-safe"},{"location":"development/architecture/#llm-extractors","title":"LLM Extractors","text":"<p>All LLM extractors are thread-safe as they use HTTP/gRPC clients that handle concurrent requests properly.</p>"},{"location":"development/architecture/#coordinate-system","title":"Coordinate System","text":"<p>All coordinates flow through a conversion pipeline:</p> <pre><code>Native Unit \u2192 Points \u2192 Output Unit\n</code></pre> <ul> <li>PDF uses points natively</li> <li>OCR uses pixels natively (at specified DPI)</li> <li>Cloud APIs may use normalized coordinates</li> </ul> <p>The <code>CoordinateConverter</code> handles all conversions.</p>"},{"location":"development/contributing/","title":"Contributing","text":""},{"location":"development/contributing/#development-setup","title":"Development Setup","text":"<pre><code># Clone the repository\ngit clone https://github.com/aptakhin/unifex.git\ncd unifex\n\n# Install dependencies\nuv sync\n\n# Install pre-commit hooks\nuv run pre-commit install\n</code></pre>"},{"location":"development/contributing/#documentation","title":"Documentation","text":"<p>Build and serve the documentation locally:</p> <pre><code># Serve docs with live reload\nuv run mkdocs serve\n\n# Build static site\nuv run mkdocs build\n</code></pre> <p>Open http://localhost:8000 to view the documentation.</p>"},{"location":"development/contributing/#testing-documentation-examples","title":"Testing Documentation Examples","text":"<p>Documentation code examples are tested using Sybil:</p> <pre><code># Run doc tests\nuv run pytest docs/\n</code></pre>"},{"location":"development/contributing/#code-style","title":"Code Style","text":"<ul> <li>Use type hints for all function signatures</li> <li>Follow existing patterns in the codebase</li> <li>Imports should be sorted (standard library, third-party, local)</li> </ul> <p>The project uses ruff for formatting and linting.</p>"},{"location":"development/contributing/#pre-commit-checks","title":"Pre-commit Checks","text":"<p>The pre-commit hook runs automatically on <code>git commit</code>. To run manually:</p> <pre><code>uv run pre-commit run --all-files\n</code></pre> <p>This runs:</p> <ul> <li><code>ruff format</code> - Code formatting</li> <li><code>ruff check --fix</code> - Linting with auto-fix</li> <li><code>ty check</code> - Type checking</li> <li><code>pytest</code> with 85% coverage requirement</li> </ul>"},{"location":"development/contributing/#pull-request-process","title":"Pull Request Process","text":"<ol> <li>Create a feature branch from <code>main</code></li> <li>Make your changes with tests</li> <li>Ensure all pre-commit checks pass</li> <li>Submit a pull request</li> </ol>"},{"location":"development/contributing/#design-principles","title":"Design Principles","text":"<ul> <li>Think about correct degree of coupling when designing components</li> <li>Prefer exceptions for invalid user input over returning error objects</li> <li>Avoid over-engineering - only make changes that are directly requested</li> </ul>"},{"location":"development/testing/","title":"Testing","text":""},{"location":"development/testing/#running-tests","title":"Running Tests","text":"<pre><code># Run all tests\nuv run pytest\n\n# Run fast tests only (unit tests, &lt;0.5s per test)\nuv run pytest tests/base tests/ocr\n\n# Run integration tests only (slow, load ML models)\nuv run pytest tests/integration\n\n# Run with coverage\nuv run pytest --cov=unifex --cov-report=term-missing\n</code></pre>"},{"location":"development/testing/#test-structure","title":"Test Structure","text":"<pre><code>tests/\n\u251c\u2500\u2500 base/           # Fast unit tests (&lt;0.5s each) - run in pre-commit\n\u251c\u2500\u2500 ocr/            # OCR adapter unit tests (mocked) - run in pre-commit\n\u251c\u2500\u2500 llm/            # LLM unit tests (mocked) - run in pre-commit\n\u2514\u2500\u2500 integration/    # Slow tests - NOT in pre-commit\n    \u251c\u2500\u2500 ocr/        # OCR integration tests (load real ML models)\n    \u2514\u2500\u2500 llm/        # LLM integration tests (call real APIs)\n</code></pre> <p>Pre-commit runs: <code>tests/base</code>, <code>tests/ocr</code>, and <code>tests/llm</code> with 0.5s timeout per test.</p> <p>CI runs: All tests including integration tests.</p>"},{"location":"development/testing/#test-data","title":"Test Data","text":"<p>Test files are located in <code>tests/data/</code>:</p> <ul> <li><code>test_pdf_2p_text.pdf</code> - 2-page PDF with text</li> <li><code>test_pdf_2p_text_rotated.pdf</code> - 2-page PDF with rotated text</li> <li><code>test_pdf_table.pdf</code> - PDF with tables</li> <li><code>test_image.png</code> - Test image for OCR</li> </ul>"},{"location":"development/testing/#integration-tests","title":"Integration Tests","text":"<p>Integration tests load real ML models and call real services.</p>"},{"location":"development/testing/#local-extractors-no-credentials-required","title":"Local Extractors (No Credentials Required)","text":"<ul> <li><code>PdfExtractor</code> - Tests PDF text extraction</li> <li><code>EasyOcrExtractor</code> - Tests image and PDF OCR with EasyOCR</li> <li><code>TesseractOcrExtractor</code> - Tests image and PDF OCR with Tesseract</li> <li><code>PaddleOcrExtractor</code> - Tests image and PDF OCR with PaddleOCR</li> </ul>"},{"location":"development/testing/#cloud-extractors-require-credentials","title":"Cloud Extractors (Require Credentials)","text":"<p>Tests are automatically skipped if credentials are not configured.</p>"},{"location":"development/testing/#azure-setup","title":"Azure Setup","text":"<pre><code>cp .env.example .env\n# Edit .env with your credentials:\n# UNIFEX_AZURE_DI_ENDPOINT=https://your-resource.cognitiveservices.azure.com\n# UNIFEX_AZURE_DI_KEY=your-api-key\n\n# Run tests\nexport $(cat .env | xargs)\nuv run pytest tests/integration -v\n</code></pre>"},{"location":"development/testing/#google-setup","title":"Google Setup","text":"<pre><code># Edit .env:\n# UNIFEX_GOOGLE_DOCAI_PROCESSOR_NAME=projects/your-project/locations/us/processors/123\n# UNIFEX_GOOGLE_DOCAI_CREDENTIALS_PATH=/path/to/service-account.json\n\nexport $(cat .env | xargs)\nuv run pytest tests/integration -v\n</code></pre>"},{"location":"development/testing/#tdd-workflow","title":"TDD Workflow","text":"<p>This project follows Test-Driven Development:</p> <ol> <li>Red - Write a failing test first</li> <li>Green - Write minimal code to pass the test</li> <li>Refactor - Clean up while keeping tests green</li> </ol>"},{"location":"development/testing/#vcr-cassettes","title":"VCR Cassettes","text":"<p>For API tests, we use VCR to record HTTP interactions:</p> <pre><code>@pytest.mark.vcr()\ndef test_api_call():\n    # First run records the cassette\n    # Subsequent runs replay it\n    ...\n</code></pre> <p>Cassettes are stored in <code>tests/cassettes/</code>.</p>"},{"location":"getting-started/installation/","title":"Installation","text":""},{"location":"getting-started/installation/#basic-installation","title":"Basic Installation","text":"<p>Install unifex using pip:</p> <pre><code>pip install unifex\n</code></pre> <p>Or using uv:</p> <pre><code>uv add unifex\n</code></pre>"},{"location":"getting-started/installation/#optional-dependencies","title":"Optional Dependencies","text":"<p>unifex uses optional dependencies to keep the base installation lightweight. Install only what you need:</p>"},{"location":"getting-started/installation/#pdf-extraction","title":"PDF Extraction","text":"<pre><code>pip install unifex[pdf]\n</code></pre>"},{"location":"getting-started/installation/#local-ocr-engines","title":"Local OCR Engines","text":"<pre><code># EasyOCR\npip install unifex[easyocr]\n\n# Tesseract (requires system Tesseract installation)\npip install unifex[tesseract]\n\n# PaddleOCR\npip install unifex[paddle]\n</code></pre>"},{"location":"getting-started/installation/#cloud-ocr-services","title":"Cloud OCR Services","text":"<pre><code># Azure Document Intelligence\npip install unifex[azure]\n\n# Google Document AI\npip install unifex[google]\n</code></pre>"},{"location":"getting-started/installation/#llm-providers","title":"LLM Providers","text":"<pre><code># OpenAI\npip install unifex[llm-openai]\n\n# Anthropic\npip install unifex[llm-anthropic]\n\n# Google Gemini\npip install unifex[llm-google]\n\n# All LLM providers\npip install unifex[llm-all]\n</code></pre>"},{"location":"getting-started/installation/#everything","title":"Everything","text":"<pre><code>pip install unifex[all]\n</code></pre>"},{"location":"getting-started/installation/#system-requirements","title":"System Requirements","text":""},{"location":"getting-started/installation/#tesseract-ocr","title":"Tesseract OCR","text":"<p>Tesseract requires system installation:</p> <ul> <li>macOS: <code>brew install tesseract</code></li> <li>Ubuntu: <code>apt-get install tesseract-ocr</code></li> <li>Windows: Download from UB-Mannheim/tesseract</li> </ul>"},{"location":"getting-started/installation/#paddleocr","title":"PaddleOCR","text":"<p>PaddleOCR works out of the box but may require additional setup for GPU acceleration.</p>"},{"location":"getting-started/quickstart/","title":"Quick Start","text":""},{"location":"getting-started/quickstart/#factory-interface-recommended","title":"Factory Interface (Recommended)","text":"<p>The simplest way to use unifex is via the factory interface:</p> <pre><code>from unifex import create_extractor, ExtractorType\n\n# PDF extraction (native text)\nwith create_extractor(\"document.pdf\", ExtractorType.PDF) as extractor:\n    result = extractor.extract()\n    print(f\"Extracted {len(result.document.pages)} pages\")\n</code></pre> <pre><code>from unifex import create_extractor, ExtractorType\n\n# EasyOCR for images\nwith create_extractor(\"image.png\", ExtractorType.EASYOCR, languages=[\"en\"]) as extractor:\n    result = extractor.extract()\n\n# EasyOCR for PDFs (auto-converts to images internally)\nwith create_extractor(\"scanned.pdf\", ExtractorType.EASYOCR, dpi=200) as extractor:\n    result = extractor.extract()\n</code></pre> <pre><code>from unifex import create_extractor, ExtractorType\n\n# Azure Document Intelligence (credentials from env vars)\nwith create_extractor(\"document.pdf\", ExtractorType.AZURE_DI) as extractor:\n    result = extractor.extract()\n</code></pre>"},{"location":"getting-started/quickstart/#understanding-the-result","title":"Understanding the Result","text":"<p>The <code>extract()</code> method returns an <code>ExtractionResult</code> containing the <code>Document</code> and per-page results:</p> <pre><code>from unifex import create_extractor, ExtractorType\n\nwith create_extractor(\"document.pdf\", ExtractorType.PDF) as extractor:\n    result = extractor.extract()\n\n# Check extraction status\nprint(f\"Success: {result.success}\")\n\n# Access extracted document\ndoc = result.document\nprint(f\"Pages: {len(doc.pages)}\")\n\nfor page in doc.pages:\n    print(f\"Page {page.page + 1} ({page.width:.0f}x{page.height:.0f}):\")\n    for text in page.texts[:2]:  # Show first 2 texts per page\n        print(f\"  - \\\"{text.text}\\\"\")\n\n# Handle errors if any\nif not result.success:\n    for page_num, error in result.errors:\n        print(f\"Page {page_num} failed: {error}\")\n</code></pre>"},{"location":"getting-started/quickstart/#direct-extractor-usage","title":"Direct Extractor Usage","text":"<p>You can also use extractors directly without the factory:</p> <pre><code>from unifex import PdfExtractor\n\nwith PdfExtractor(\"document.pdf\") as extractor:\n    result = extractor.extract()\n    for page in result.document.pages:\n        for text in page.texts[:2]:  # Show first 2 texts per page\n            print(text.text)\n</code></pre>"},{"location":"getting-started/quickstart/#next-steps","title":"Next Steps","text":"<ul> <li>PDF Extraction - Native PDF text extraction</li> <li>OCR Extraction - Local and cloud OCR options</li> <li>LLM Extraction - Structured data extraction with LLMs</li> <li>Parallel Processing - Speed up extraction with parallelism</li> </ul>"},{"location":"guide/async-api/","title":"Async API","text":"<p>unifex provides native async/await support for integration with async applications.</p>"},{"location":"guide/async-api/#basic-async-extraction","title":"Basic Async Extraction","text":"<pre><code>import asyncio\nfrom unifex import create_extractor, ExtractorType\n\nasync def extract_document():\n    with create_extractor(\"document.pdf\", ExtractorType.PDF) as extractor:\n        result = await extractor.extract_async(max_workers=2)\n        return result.document\n\ndoc = asyncio.run(extract_document())\nprint(f\"Extracted {len(doc.pages)} pages asynchronously\")\n</code></pre>"},{"location":"guide/async-api/#async-llm-extraction","title":"Async LLM Extraction","text":"<pre><code>import asyncio\nfrom unifex.llm import extract_structured_async\n\nasync def extract():\n    result = await extract_structured_async(\n        \"document.pdf\",\n        model=\"openai/gpt-4o\",\n        max_workers=4,\n    )\n    return result.data\n\ndata = asyncio.run(extract())\n</code></pre>"},{"location":"guide/async-api/#using-with-fastapi","title":"Using with FastAPI","text":"<pre><code>from fastapi import FastAPI, UploadFile\nfrom unifex import create_extractor, ExtractorType\n\napp = FastAPI()\n\n@app.post(\"/extract\")\nasync def extract_document(file: UploadFile):\n    # Save uploaded file temporarily\n    content = await file.read()\n    temp_path = f\"/tmp/{file.filename}\"\n    with open(temp_path, \"wb\") as f:\n        f.write(content)\n\n    # Extract asynchronously\n    with create_extractor(temp_path, ExtractorType.PDF) as extractor:\n        result = await extractor.extract_async()\n        return {\"pages\": len(result.document.pages)}\n</code></pre>"},{"location":"guide/async-api/#concurrent-document-processing","title":"Concurrent Document Processing","text":"<p>Process multiple documents concurrently:</p> <pre><code>import asyncio\nfrom unifex import create_extractor, ExtractorType\n\nasync def extract_one(path: str):\n    with create_extractor(path, ExtractorType.PDF) as extractor:\n        return await extractor.extract_async()\n\nasync def extract_many(paths: list[str]):\n    tasks = [extract_one(p) for p in paths]\n    return await asyncio.gather(*tasks)\n\n# Using the same file twice for demo\npaths = [\"document.pdf\", \"document.pdf\"]\nresults = asyncio.run(extract_many(paths))\nprint(f\"Extracted {len(results)} documents concurrently\")\n</code></pre>"},{"location":"guide/cli/","title":"CLI Usage","text":"<p>unifex provides a command-line interface for document extraction.</p>"},{"location":"guide/cli/#basic-commands","title":"Basic Commands","text":""},{"location":"guide/cli/#pdf-extraction","title":"PDF Extraction","text":"<pre><code>uv run python -m unifex.cli document.pdf --extractor pdf\n</code></pre>"},{"location":"guide/cli/#ocr-extraction","title":"OCR Extraction","text":"<pre><code># EasyOCR (works for both images and PDFs)\nuv run python -m unifex.cli image.png --extractor easyocr --lang en\nuv run python -m unifex.cli scanned.pdf --extractor easyocr --lang en\n\n# Tesseract\nuv run python -m unifex.cli document.pdf --extractor tesseract --lang eng\n\n# PaddleOCR\nuv run python -m unifex.cli document.pdf --extractor paddle --lang en\n</code></pre>"},{"location":"guide/cli/#cloud-ocr","title":"Cloud OCR","text":"<pre><code># Azure Document Intelligence\nuv run python -m unifex.cli document.pdf --extractor azure-di \\\n    --azure-endpoint https://your-resource.cognitiveservices.azure.com \\\n    --azure-key your-api-key\n\n# Google Document AI\nuv run python -m unifex.cli document.pdf --extractor google-docai \\\n    --google-processor-name projects/your-project/locations/us/processors/123 \\\n    --google-credentials-path /path/to/credentials.json\n</code></pre>"},{"location":"guide/cli/#parallel-processing","title":"Parallel Processing","text":"<pre><code># Use 4 parallel workers\nuv run python -m unifex.cli document.pdf --extractor pdf --workers 4\n\n# Use process executor instead of threads\nuv run python -m unifex.cli document.pdf --extractor pdf --workers 4 --executor process\n</code></pre>"},{"location":"guide/cli/#output-formats","title":"Output Formats","text":"<pre><code># JSON output\nuv run python -m unifex.cli document.pdf --extractor pdf --json\n\n# Specific pages\nuv run python -m unifex.cli document.pdf --extractor pdf --pages 0,1\n</code></pre>"},{"location":"guide/cli/#llm-extraction","title":"LLM Extraction","text":"<pre><code># Free-form extraction\nuv run python -m unifex.cli document.pdf --llm openai/gpt-4o\n\n# With custom prompt\nuv run python -m unifex.cli image.png --llm anthropic/claude-sonnet-4-20250514 \\\n    --llm-prompt \"Extract all text from this image\"\n\n# With parallel workers\nuv run python -m unifex.cli document.pdf --llm openai/gpt-4o --workers 4\n\n# With OpenAI-compatible API\nuv run python -m unifex.cli document.pdf --llm openai/llava \\\n    --llm-base-url http://localhost:11434/v1\n\n# With custom headers\nuv run python -m unifex.cli document.pdf --llm openai/gpt-4o \\\n    --llm-base-url https://your-proxy.com/v1 \\\n    --llm-header \"X-Custom-Auth=your-token\"\n\n# JSON output\nuv run python -m unifex.cli document.pdf --llm openai/gpt-4o --json\n</code></pre>"},{"location":"guide/cli/#environment-variables","title":"Environment Variables","text":"<p>Instead of passing credentials via CLI, you can use environment variables:</p> <pre><code># Azure\nexport UNIFEX_AZURE_DI_ENDPOINT=https://your-resource.cognitiveservices.azure.com\nexport UNIFEX_AZURE_DI_KEY=your-api-key\nuv run python -m unifex.cli document.pdf --extractor azure-di\n\n# Google\nexport UNIFEX_GOOGLE_DOCAI_PROCESSOR_NAME=projects/your-project/locations/us/processors/123\nexport UNIFEX_GOOGLE_DOCAI_CREDENTIALS_PATH=/path/to/credentials.json\nuv run python -m unifex.cli document.pdf --extractor google-docai\n\n# LLM\nexport OPENAI_API_KEY=your-key\nuv run python -m unifex.cli document.pdf --llm openai/gpt-4o\n</code></pre>"},{"location":"guide/llm-extraction/","title":"LLM Extraction","text":"<p>Extract structured data from documents using vision-capable LLMs.</p>"},{"location":"guide/llm-extraction/#supported-providers","title":"Supported Providers","text":"<ul> <li>OpenAI: GPT-4o, GPT-4o-mini</li> <li>Anthropic: Claude Sonnet, Claude Opus</li> <li>Google: Gemini Pro, Gemini Flash</li> <li>Azure OpenAI: GPT-4o via Azure</li> <li>OpenAI-Compatible: vLLM, Ollama, and other compatible APIs</li> </ul>"},{"location":"guide/llm-extraction/#basic-usage","title":"Basic Usage","text":""},{"location":"guide/llm-extraction/#free-form-extraction","title":"Free-form Extraction","text":"<pre><code>from unifex.llm import extract_structured\n\nresult = extract_structured(\n    \"document.pdf\",\n    model=\"openai/gpt-4o\",\n)\nprint(result.data)\n</code></pre>"},{"location":"guide/llm-extraction/#with-custom-prompt","title":"With Custom Prompt","text":"<pre><code>from unifex.llm import extract_structured\n\nresult = extract_structured(\n    \"image.png\",\n    model=\"anthropic/claude-sonnet-4-20250514\",\n    prompt=\"Extract all visible text from this image\",\n)\n</code></pre>"},{"location":"guide/llm-extraction/#structured-extraction-with-pydantic","title":"Structured Extraction with Pydantic","text":"<p>Define a Pydantic model for type-safe structured output:</p> <pre><code>from pydantic import BaseModel\nfrom unifex.llm import extract_structured\n\nclass DocumentContent(BaseModel):\n    title: str | None\n    paragraphs: list[str]\n\nresult = extract_structured(\n    \"document.pdf\",\n    model=\"openai/gpt-4o\",\n    schema=DocumentContent,\n)\ncontent: DocumentContent = result.data\nprint(f\"Found {len(content.paragraphs)} paragraphs\")\n</code></pre>"},{"location":"guide/llm-extraction/#openai-compatible-apis","title":"OpenAI-Compatible APIs","text":"<p>Use custom base URLs for self-hosted or alternative APIs:</p> <pre><code>from unifex.llm import extract_structured\n\n# vLLM server\nresult = extract_structured(\n    \"document.pdf\",\n    model=\"openai/meta-llama/Llama-3.2-90B-Vision-Instruct\",\n    base_url=\"http://localhost:8000/v1\",\n)\n\n# Ollama\nresult = extract_structured(\n    \"image.png\",\n    model=\"openai/llava\",\n    base_url=\"http://localhost:11434/v1\",\n)\n\n# With custom headers\nresult = extract_structured(\n    \"document.pdf\",\n    model=\"openai/gpt-4o\",\n    base_url=\"https://your-proxy.com/v1\",\n    headers={\"X-Custom-Auth\": \"your-token\"},\n)\n</code></pre>"},{"location":"guide/llm-extraction/#parallel-extraction","title":"Parallel Extraction","text":"<p>Process multiple pages in parallel for faster extraction:</p> <pre><code>from unifex.llm import extract_structured\n\n# Sequential: all pages sent in one request (default)\nresult = extract_structured(\"document.pdf\", model=\"openai/gpt-4o\")\n\n# Parallel: each page processed separately with 4 concurrent workers\nresult = extract_structured(\n    \"document.pdf\",\n    model=\"openai/gpt-4o\",\n    max_workers=4,\n)\n# result.data is a list of per-page results\n# result.usage contains aggregated token usage\n</code></pre>"},{"location":"guide/llm-extraction/#async-api","title":"Async API","text":"<pre><code>import asyncio\nfrom unifex.llm import extract_structured_async\n\nasync def extract():\n    result = await extract_structured_async(\n        \"document.pdf\",\n        model=\"openai/gpt-4o\",\n        max_workers=4,\n    )\n    return result.data\n\ndata = asyncio.run(extract())\n</code></pre>"},{"location":"guide/llm-extraction/#environment-variables","title":"Environment Variables","text":"Variable Description <code>OPENAI_API_KEY</code> OpenAI API key <code>ANTHROPIC_API_KEY</code> Anthropic API key <code>GOOGLE_API_KEY</code> Google AI API key <code>AZURE_OPENAI_API_KEY</code> Azure OpenAI API key <code>AZURE_OPENAI_ENDPOINT</code> Azure OpenAI endpoint URL <code>AZURE_OPENAI_API_VERSION</code> Azure OpenAI API version"},{"location":"guide/ocr-extraction/","title":"OCR Extraction","text":"<p>unifex supports multiple OCR backends for extracting text from images and scanned PDFs.</p>"},{"location":"guide/ocr-extraction/#language-codes","title":"Language Codes","text":"<p>All OCR extractors use 2-letter ISO 639-1 language codes (e.g., <code>\"en\"</code>, <code>\"fr\"</code>, <code>\"de\"</code>, <code>\"it\"</code>). Extractors that require different formats (like Tesseract) convert internally.</p>"},{"location":"guide/ocr-extraction/#local-ocr-engines","title":"Local OCR Engines","text":""},{"location":"guide/ocr-extraction/#easyocr","title":"EasyOCR","text":"<pre><code>from unifex import EasyOcrExtractor\n\n# For images\nwith EasyOcrExtractor(\"image.png\", languages=[\"en\"]) as extractor:\n    result = extractor.extract()\n\n# For PDFs (auto-converts to images)\nwith EasyOcrExtractor(\"scanned.pdf\", languages=[\"en\"], dpi=200) as extractor:\n    result = extractor.extract()\n</code></pre>"},{"location":"guide/ocr-extraction/#tesseract","title":"Tesseract","text":"<p>Requires Tesseract to be installed on the system:</p> <ul> <li>macOS: <code>brew install tesseract</code></li> <li>Ubuntu: <code>apt-get install tesseract-ocr</code></li> <li>Windows: Download from UB-Mannheim/tesseract</li> </ul> <pre><code>from unifex import TesseractOcrExtractor\n\n# For images\nwith TesseractOcrExtractor(\"image.png\", languages=[\"en\"]) as extractor:\n    result = extractor.extract()\n\n# For PDFs (auto-converts to images)\nwith TesseractOcrExtractor(\"scanned.pdf\", languages=[\"en\"], dpi=200) as extractor:\n    result = extractor.extract()\n</code></pre>"},{"location":"guide/ocr-extraction/#paddleocr","title":"PaddleOCR","text":"<p>Excellent accuracy for multiple languages, especially Chinese.</p> <pre><code>from unifex import PaddleOcrExtractor\n\n# For images\nwith PaddleOcrExtractor(\"image.png\", lang=\"en\") as extractor:\n    result = extractor.extract()\n\n# For PDFs (auto-converts to images)\nwith PaddleOcrExtractor(\"scanned.pdf\", lang=\"en\", dpi=200) as extractor:\n    result = extractor.extract()\n\n# For Chinese text\nwith PaddleOcrExtractor(\"chinese_doc.png\", lang=\"ch\") as extractor:\n    result = extractor.extract()\n</code></pre>"},{"location":"guide/ocr-extraction/#cloud-ocr-services","title":"Cloud OCR Services","text":""},{"location":"guide/ocr-extraction/#azure-document-intelligence","title":"Azure Document Intelligence","text":"<pre><code>from unifex import AzureDocumentIntelligenceExtractor\n\nwith AzureDocumentIntelligenceExtractor(\n    \"document.pdf\",\n    endpoint=\"https://your-resource.cognitiveservices.azure.com\",\n    key=\"your-api-key\",\n) as extractor:\n    result = extractor.extract()\n</code></pre> <p>Or use environment variables:</p> <pre><code>export UNIFEX_AZURE_DI_ENDPOINT=https://your-resource.cognitiveservices.azure.com\nexport UNIFEX_AZURE_DI_KEY=your-api-key\n</code></pre>"},{"location":"guide/ocr-extraction/#google-document-ai","title":"Google Document AI","text":"<pre><code>from unifex import GoogleDocumentAIExtractor\n\nwith GoogleDocumentAIExtractor(\n    \"document.pdf\",\n    processor_name=\"projects/your-project/locations/us/processors/your-processor-id\",\n    credentials_path=\"/path/to/service-account.json\",\n) as extractor:\n    result = extractor.extract()\n</code></pre> <p>Or use environment variables:</p> <pre><code>export UNIFEX_GOOGLE_DOCAI_PROCESSOR_NAME=projects/your-project/locations/us/processors/123\nexport UNIFEX_GOOGLE_DOCAI_CREDENTIALS_PATH=/path/to/credentials.json\n</code></pre>"},{"location":"guide/ocr-extraction/#parallel-extraction","title":"Parallel Extraction","text":"<p>All OCR extractors support parallel page extraction:</p> <pre><code>from unifex import EasyOcrExtractor\n\nwith EasyOcrExtractor(\"scanned.pdf\", languages=[\"en\"]) as extractor:\n    result = extractor.extract(max_workers=4)\n</code></pre> <p>See Parallel Processing for more details.</p>"},{"location":"guide/ocr-extraction/#coordinate-units","title":"Coordinate Units","text":"<p>Control the output coordinate system:</p> <pre><code>from unifex import EasyOcrExtractor, CoordinateUnit\n\n# Pixels (default for OCR, uses DPI for conversion)\nwith EasyOcrExtractor(\"image.png\", languages=[\"en\"],\n                       output_unit=CoordinateUnit.PIXELS, dpi=150) as extractor:\n    result = extractor.extract()\n\n# Points (1/72 inch)\nwith EasyOcrExtractor(\"image.png\", languages=[\"en\"],\n                       output_unit=CoordinateUnit.POINTS) as extractor:\n    result = extractor.extract()\n\n# Normalized (0-1 range)\nwith EasyOcrExtractor(\"image.png\", languages=[\"en\"],\n                       output_unit=CoordinateUnit.NORMALIZED) as extractor:\n    result = extractor.extract()\n</code></pre>"},{"location":"guide/ocr-extraction/#choosing-an-ocr-engine","title":"Choosing an OCR Engine","text":"Engine Best For Speed Accuracy EasyOCR General purpose, many languages Medium High Tesseract Fast processing, good accuracy Fast Medium-High PaddleOCR Chinese text, high accuracy Medium Very High Azure DI Production workloads, tables Fast Very High Google DocAI Production workloads, forms Fast Very High"},{"location":"guide/parallel-processing/","title":"Parallel Processing","text":"<p>Extract multiple pages concurrently for faster processing.</p>"},{"location":"guide/parallel-processing/#basic-parallel-extraction","title":"Basic Parallel Extraction","text":"<pre><code>from unifex import create_extractor, ExtractorType\n\nwith create_extractor(\"document.pdf\", ExtractorType.PDF) as extractor:\n    result = extractor.extract(max_workers=2)\n    print(f\"Extracted {len(result.document.pages)} pages\")\n</code></pre>"},{"location":"guide/parallel-processing/#executor-types","title":"Executor Types","text":"<p>unifex supports two executor types for parallel processing:</p>"},{"location":"guide/parallel-processing/#thread-executor-default","title":"Thread Executor (Default)","text":"<p>Best for most OCR use cases. Threads share the model cache and have low overhead.</p> <pre><code>from unifex import create_extractor, ExtractorType, ExecutorType\n\nwith create_extractor(\"document.pdf\", ExtractorType.PDF) as extractor:\n    result = extractor.extract(max_workers=2, executor=ExecutorType.THREAD)\n    print(f\"Thread executor: {len(result.document.pages)} pages\")\n</code></pre>"},{"location":"guide/parallel-processing/#process-executor","title":"Process Executor","text":"<p>Best for CPU-bound pure Python workloads. Models are duplicated per worker, resulting in higher memory usage.</p> <pre><code>from unifex import create_extractor, ExtractorType, ExecutorType\n\nwith create_extractor(\"document.pdf\", ExtractorType.PDF) as extractor:\n    result = extractor.extract(max_workers=2, executor=ExecutorType.PROCESS)\n    print(f\"Process executor: {len(result.document.pages)} pages\")\n</code></pre>"},{"location":"guide/parallel-processing/#comparison","title":"Comparison","text":"Executor Best For Notes <code>THREAD</code> (default) Most OCR use cases Shared model cache, low overhead, C libraries release GIL <code>PROCESS</code> CPU-bound pure Python Models duplicated per worker, higher memory usage"},{"location":"guide/parallel-processing/#extracting-specific-pages-in-parallel","title":"Extracting Specific Pages in Parallel","text":"<pre><code>from unifex import create_extractor, ExtractorType\n\nwith create_extractor(\"document.pdf\", ExtractorType.PDF) as extractor:\n    result = extractor.extract(pages=[0, 1], max_workers=2)\n    print(f\"Extracted pages: {[p.page for p in result.document.pages]}\")\n</code></pre>"},{"location":"guide/parallel-processing/#llm-parallel-extraction","title":"LLM Parallel Extraction","text":"<p>LLM extraction also supports parallel processing:</p> <pre><code>from unifex.llm import extract_structured\n\nresult = extract_structured(\n    \"document.pdf\",\n    model=\"openai/gpt-4o\",\n    max_workers=4,\n)\n# result.data is a list of per-page results\n</code></pre>"},{"location":"guide/pdf-extraction/","title":"PDF Extraction","text":"<p>Native PDF text extraction using pypdfium2, with optional table extraction via tabula-py.</p>"},{"location":"guide/pdf-extraction/#basic-usage","title":"Basic Usage","text":"<pre><code>from unifex import PdfExtractor\n\nwith PdfExtractor(\"document.pdf\") as extractor:\n    result = extractor.extract()\n    for page in result.document.pages:\n        for text in page.texts[:2]:  # Show first 2 texts\n            print(text.text)\n</code></pre>"},{"location":"guide/pdf-extraction/#using-the-factory","title":"Using the Factory","text":"<pre><code>from unifex import create_extractor, ExtractorType\n\nwith create_extractor(\"document.pdf\", ExtractorType.PDF) as extractor:\n    result = extractor.extract()\n    print(f\"Extracted {len(result.document.pages)} pages\")\n</code></pre>"},{"location":"guide/pdf-extraction/#extracting-specific-pages","title":"Extracting Specific Pages","text":"<pre><code>from unifex import PdfExtractor\n\nwith PdfExtractor(\"document.pdf\") as extractor:\n    # Extract only page 0\n    result = extractor.extract(pages=[0])\n    print(f\"Extracted page: {result.document.pages[0].page}\")\n</code></pre>"},{"location":"guide/pdf-extraction/#parallel-extraction","title":"Parallel Extraction","text":"<p>Extract multiple pages concurrently for faster processing:</p> <pre><code>from unifex import PdfExtractor\n\nwith PdfExtractor(\"document.pdf\") as extractor:\n    # Use 2 parallel workers\n    result = extractor.extract(max_workers=2)\n    print(f\"Extracted {len(result.document.pages)} pages in parallel\")\n</code></pre> <p>See Parallel Processing for more details.</p>"},{"location":"guide/pdf-extraction/#coordinate-units","title":"Coordinate Units","text":"<p>Control the output coordinate system for bounding boxes:</p> <pre><code>from unifex import PdfExtractor, CoordinateUnit\n\n# Points (default) - 1/72 inch, PDF native\nwith PdfExtractor(\"document.pdf\", output_unit=CoordinateUnit.POINTS) as extractor:\n    result = extractor.extract()\n    print(f\"Points: {result.document.pages[0].texts[0].bbox}\")\n\n# Inches\nwith PdfExtractor(\"document.pdf\", output_unit=CoordinateUnit.INCHES) as extractor:\n    result = extractor.extract()\n    print(f\"Inches: {result.document.pages[0].texts[0].bbox}\")\n\n# Normalized (0-1 range relative to page dimensions)\nwith PdfExtractor(\"document.pdf\", output_unit=CoordinateUnit.NORMALIZED) as extractor:\n    result = extractor.extract()\n    print(f\"Normalized: {result.document.pages[0].texts[0].bbox}\")\n</code></pre> <p>Available units:</p> Unit Description <code>POINTS</code> 1/72 inch (PDF native, resolution-independent) <code>PIXELS</code> Pixels at specified DPI (not supported for PDF) <code>INCHES</code> Imperial inches <code>NORMALIZED</code> 0-1 range relative to page dimensions <p>Note</p> <p>PDF extractor doesn't support <code>PIXELS</code> output because PDFs don't have inherent DPI.</p>"},{"location":"guide/pdf-extraction/#table-extraction","title":"Table Extraction","text":"<p>Extract tables from PDFs using tabula-py. Requires the <code>tables</code> extra:</p> <pre><code>uv sync --extra tables\n</code></pre>"},{"location":"guide/pdf-extraction/#basic-table-extraction","title":"Basic Table Extraction","text":"<pre><code>from unifex import PdfExtractor\n\nwith PdfExtractor(\"table.pdf\") as extractor:\n    result = extractor.extract(table_options={})\n    for page in result.document.pages:\n        for table in page.tables:\n            print(f\"Table with {len(table.rows)} rows\")\n            for row in table.rows:\n                print([cell.text for cell in row])\n</code></pre>"},{"location":"guide/pdf-extraction/#table-options","title":"Table Options","text":"<p>Pass tabula options to control extraction behavior. Coordinates in <code>area</code> and <code>columns</code> follow the extractor's <code>output_unit</code> setting (default: <code>POINTS</code>).</p> <pre><code>from unifex import PdfExtractor, CoordinateUnit\n\nwith PdfExtractor(\"table.pdf\") as extractor:\n    # Lattice mode: for tables with visible borders\n    result = extractor.extract(table_options={\"lattice\": True})\n\n    # Stream mode: for tables without visible borders\n    result = extractor.extract(table_options={\"stream\": True})\n\n    # Extract from specific area (top, left, bottom, right in points - the default)\n    result = extractor.extract(table_options={\n        \"area\": (100, 50, 400, 500),\n        \"columns\": [100, 200, 350],  # column boundaries in points\n    })\n\n    # Multiple tables per page\n    result = extractor.extract(table_options={\"multiple_tables\": True})\n\n# Using inches instead of points\nwith PdfExtractor(\"table.pdf\", output_unit=CoordinateUnit.INCHES) as extractor:\n    result = extractor.extract(table_options={\n        \"area\": (1.0, 0.5, 5.0, 7.0),   # in inches\n        \"columns\": [1.5, 3.0, 5.5],      # in inches\n    })\n</code></pre>"},{"location":"guide/pdf-extraction/#path-objects","title":"Path Objects","text":"<p>Both string paths and <code>Path</code> objects are supported:</p> <pre><code>from pathlib import Path\nfrom unifex import PdfExtractor\n\nwith PdfExtractor(Path(\"document.pdf\")) as extractor:\n    result = extractor.extract()\n    print(f\"Extracted {len(result.document.pages)} pages\")\n</code></pre>"},{"location":"guide/pdf-extraction/#when-to-use-pdf-extraction","title":"When to Use PDF Extraction","text":"<p>PDF extraction is ideal for:</p> <ul> <li>Documents with embedded text (not scanned images)</li> <li>High-quality PDFs where text is selectable</li> <li>When you need precise character positioning</li> <li>Extracting structured tables from PDFs</li> </ul> <p>For scanned PDFs or images, use OCR Extraction instead.</p>"},{"location":"reference/api/","title":"API Reference","text":""},{"location":"reference/api/#factory-function","title":"Factory Function","text":""},{"location":"reference/api/#create_extractor","title":"create_extractor","text":"<p>The main entry point for creating extractors.</p>"},{"location":"reference/api/#unifex.create_extractor","title":"<code>unifex.create_extractor(path, extractor_type, *, languages=None, dpi=200, use_gpu=False, credentials=None, output_unit=CoordinateUnit.POINTS, character_merger=None)</code>","text":"<p>Create an extractor by type with unified parameters.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path | str</code> <p>Path to document/image file (Path object or string).</p> required <code>extractor_type</code> <code>ExtractorType</code> <p>ExtractorType enum value specifying which extractor to use: - ExtractorType.PDF - Native PDF extraction - ExtractorType.EASYOCR - EasyOCR for images and PDFs (auto-detects) - ExtractorType.TESSERACT - Tesseract for images and PDFs (auto-detects) - ExtractorType.PADDLE - PaddleOCR for images and PDFs (auto-detects) - ExtractorType.AZURE_DI - Azure Document Intelligence - ExtractorType.GOOGLE_DOCAI - Google Document AI</p> required <code>languages</code> <code>list[str] | None</code> <p>Language codes for OCR (default: [\"en\"]). EasyOCR/Tesseract use full list, PaddleOCR uses first language.</p> <code>None</code> <code>dpi</code> <code>int</code> <p>DPI for PDF-to-image conversion (default: 200).</p> <code>200</code> <code>use_gpu</code> <code>bool</code> <p>Enable GPU acceleration where supported (default: False).</p> <code>False</code> <code>credentials</code> <code>dict[str, str] | None</code> <p>Override credentials dict. If None, reads from env vars: - UNIFEX_AZURE_DI_ENDPOINT, UNIFEX_AZURE_DI_KEY for Azure - UNIFEX_GOOGLE_DOCAI_PROCESSOR_NAME, UNIFEX_GOOGLE_DOCAI_CREDENTIALS_PATH for Google</p> <code>None</code> <code>output_unit</code> <code>CoordinateUnit</code> <p>Coordinate unit for output (default: POINTS). - CoordinateUnit.POINTS - 1/72 inch (PDF native, resolution-independent) - CoordinateUnit.PIXELS - Pixels at the specified DPI - CoordinateUnit.INCHES - Imperial inches - CoordinateUnit.NORMALIZED - 0-1 range relative to page dimensions</p> <code>POINTS</code> <code>character_merger</code> <code>str | None</code> <p>Character merger strategy for PDF extractor (default: basic-line). - \"basic-line\" - Merge characters into lines - \"keep-char\" - Keep each character as separate TextBlock</p> <code>None</code> <p>Returns:</p> Type Description <code>BaseExtractor</code> <p>Configured extractor instance.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If extractor_type is invalid or required credentials are missing.</p> Example <p>from unifex import create_extractor, ExtractorType, CoordinateUnit with create_extractor(\"doc.pdf\", ExtractorType.PDF) as ext: ...     doc = ext.extract()  # Coordinates in points (default) with create_extractor(\"doc.pdf\", ExtractorType.EASYOCR, ...                       output_unit=CoordinateUnit.PIXELS) as ext: ...     doc = ext.extract()  # Coordinates in pixels</p> Source code in <code>unifex/text_factory.py</code> <pre><code>def create_extractor(  # noqa: PLR0913\n    path: Path | str,\n    extractor_type: ExtractorType,\n    *,\n    languages: list[str] | None = None,\n    dpi: int = 200,\n    use_gpu: bool = False,\n    credentials: dict[str, str] | None = None,\n    output_unit: CoordinateUnit = CoordinateUnit.POINTS,\n    character_merger: str | None = None,\n) -&gt; BaseExtractor:\n    \"\"\"Create an extractor by type with unified parameters.\n\n    Args:\n        path: Path to document/image file (Path object or string).\n        extractor_type: ExtractorType enum value specifying which extractor to use:\n            - ExtractorType.PDF - Native PDF extraction\n            - ExtractorType.EASYOCR - EasyOCR for images and PDFs (auto-detects)\n            - ExtractorType.TESSERACT - Tesseract for images and PDFs (auto-detects)\n            - ExtractorType.PADDLE - PaddleOCR for images and PDFs (auto-detects)\n            - ExtractorType.AZURE_DI - Azure Document Intelligence\n            - ExtractorType.GOOGLE_DOCAI - Google Document AI\n        languages: Language codes for OCR (default: [\"en\"]).\n            EasyOCR/Tesseract use full list, PaddleOCR uses first language.\n        dpi: DPI for PDF-to-image conversion (default: 200).\n        use_gpu: Enable GPU acceleration where supported (default: False).\n        credentials: Override credentials dict. If None, reads from env vars:\n            - UNIFEX_AZURE_DI_ENDPOINT, UNIFEX_AZURE_DI_KEY for Azure\n            - UNIFEX_GOOGLE_DOCAI_PROCESSOR_NAME, UNIFEX_GOOGLE_DOCAI_CREDENTIALS_PATH for Google\n        output_unit: Coordinate unit for output (default: POINTS).\n            - CoordinateUnit.POINTS - 1/72 inch (PDF native, resolution-independent)\n            - CoordinateUnit.PIXELS - Pixels at the specified DPI\n            - CoordinateUnit.INCHES - Imperial inches\n            - CoordinateUnit.NORMALIZED - 0-1 range relative to page dimensions\n        character_merger: Character merger strategy for PDF extractor (default: basic-line).\n            - \"basic-line\" - Merge characters into lines\n            - \"keep-char\" - Keep each character as separate TextBlock\n\n    Returns:\n        Configured extractor instance.\n\n    Raises:\n        ValueError: If extractor_type is invalid or required credentials are missing.\n\n    Example:\n        &gt;&gt;&gt; from unifex import create_extractor, ExtractorType, CoordinateUnit\n        &gt;&gt;&gt; with create_extractor(\"doc.pdf\", ExtractorType.PDF) as ext:\n        ...     doc = ext.extract()  # Coordinates in points (default)\n        &gt;&gt;&gt; with create_extractor(\"doc.pdf\", ExtractorType.EASYOCR,\n        ...                       output_unit=CoordinateUnit.PIXELS) as ext:\n        ...     doc = ext.extract()  # Coordinates in pixels\n    \"\"\"\n    languages = languages or [\"en\"]\n\n    if extractor_type == ExtractorType.PDF:\n        from unifex.pdf import PdfExtractor\n\n        merger = get_character_merger(character_merger) if character_merger else None\n        return PdfExtractor(path, output_unit=output_unit, character_merger=merger)\n\n    elif extractor_type == ExtractorType.EASYOCR:\n        from unifex.ocr.extractors.easy_ocr import EasyOcrExtractor\n\n        return EasyOcrExtractor(\n            path, languages=languages, gpu=use_gpu, dpi=dpi, output_unit=output_unit\n        )\n\n    elif extractor_type == ExtractorType.TESSERACT:\n        from unifex.ocr.extractors.tesseract_ocr import TesseractOcrExtractor\n\n        return TesseractOcrExtractor(path, languages=languages, dpi=dpi, output_unit=output_unit)\n\n    elif extractor_type == ExtractorType.PADDLE:\n        from unifex.ocr.extractors.paddle_ocr import PaddleOcrExtractor\n\n        # PaddleOCR uses single language string\n        lang = languages[0] if languages else \"en\"\n        return PaddleOcrExtractor(\n            path, lang=lang, use_gpu=use_gpu, dpi=dpi, output_unit=output_unit\n        )\n\n    elif extractor_type == ExtractorType.AZURE_DI:\n        from unifex.ocr.extractors.azure_di import AzureDocumentIntelligenceExtractor\n\n        endpoint = _get_credential(\"UNIFEX_AZURE_DI_ENDPOINT\", credentials)\n        key = _get_credential(\"UNIFEX_AZURE_DI_KEY\", credentials)\n\n        if not endpoint or not key:\n            raise ValueError(\n                \"Azure credentials required. Set UNIFEX_AZURE_DI_ENDPOINT and UNIFEX_AZURE_DI_KEY \"\n                \"environment variables or pass credentials dict.\"\n            )\n\n        return AzureDocumentIntelligenceExtractor(\n            path, endpoint=endpoint, key=key, output_unit=output_unit\n        )\n\n    elif extractor_type == ExtractorType.GOOGLE_DOCAI:\n        from unifex.ocr.extractors.google_docai import GoogleDocumentAIExtractor\n\n        processor_name = _get_credential(\"UNIFEX_GOOGLE_DOCAI_PROCESSOR_NAME\", credentials)\n        credentials_path = _get_credential(\"UNIFEX_GOOGLE_DOCAI_CREDENTIALS_PATH\", credentials)\n\n        if not processor_name:\n            raise ValueError(\n                \"Google Document AI processor name required. \"\n                \"Set UNIFEX_GOOGLE_DOCAI_PROCESSOR_NAME env var or pass credentials dict.\"\n            )\n\n        if not credentials_path:\n            raise ValueError(\n                \"Google Document AI credentials path required. \"\n                \"Set UNIFEX_GOOGLE_DOCAI_CREDENTIALS_PATH env var or pass credentials dict.\"\n            )\n\n        return GoogleDocumentAIExtractor(\n            path,\n            processor_name=processor_name,\n            credentials_path=credentials_path,\n            output_unit=output_unit,\n        )\n\n    else:\n        raise ValueError(f\"Unknown extractor type: {extractor_type}\")\n</code></pre>"},{"location":"reference/api/#extractor-types","title":"Extractor Types","text":""},{"location":"reference/api/#extractortype","title":"ExtractorType","text":"<p>Enum for available extractor types.</p>"},{"location":"reference/api/#unifex.ExtractorType","title":"<code>unifex.ExtractorType</code>","text":"<p>               Bases: <code>StrEnum</code></p> Source code in <code>unifex/base/models.py</code> <pre><code>class ExtractorType(StrEnum):\n    PDF = \"pdf\"\n    EASYOCR = \"easyocr\"\n    TESSERACT = \"tesseract\"\n    PADDLE = \"paddle\"\n    AZURE_DI = \"azure-di\"\n    GOOGLE_DOCAI = \"google-docai\"\n</code></pre>"},{"location":"reference/api/#coordinate-units","title":"Coordinate Units","text":""},{"location":"reference/api/#coordinateunit","title":"CoordinateUnit","text":"<p>Enum for coordinate output units.</p>"},{"location":"reference/api/#unifex.CoordinateUnit","title":"<code>unifex.CoordinateUnit</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>Units for coordinate output.</p> Source code in <code>unifex/base/models.py</code> <pre><code>class CoordinateUnit(StrEnum):\n    \"\"\"Units for coordinate output.\"\"\"\n\n    PIXELS = \"pixels\"  # Image pixels at a given DPI\n    POINTS = \"points\"  # 1/72 inch (PDF native, default)\n    INCHES = \"inches\"  # Imperial inches\n    NORMALIZED = \"normalized\"  # 0-1 relative to page dimensions\n</code></pre>"},{"location":"reference/api/#executor-types","title":"Executor Types","text":""},{"location":"reference/api/#executortype","title":"ExecutorType","text":"<p>Enum for parallel execution modes.</p>"},{"location":"reference/api/#unifex.base.ExecutorType","title":"<code>unifex.base.ExecutorType</code>","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>Type of executor for parallel extraction.</p> Source code in <code>unifex/base/base.py</code> <pre><code>class ExecutorType(str, Enum):\n    \"\"\"Type of executor for parallel extraction.\"\"\"\n\n    THREAD = \"thread\"\n    PROCESS = \"process\"\n</code></pre>"},{"location":"reference/configuration/","title":"Configuration Reference","text":""},{"location":"reference/configuration/#pdf-extractor-parameters","title":"PDF Extractor Parameters","text":""},{"location":"reference/configuration/#constructor-parameters","title":"Constructor Parameters","text":"Parameter Type Default Description <code>path</code> <code>Path \\| str</code> required Path to the PDF file <code>output_unit</code> <code>CoordinateUnit</code> <code>POINTS</code> Output coordinate unit <code>character_merger</code> <code>CharacterMerger</code> <code>BasicLineMerger()</code> Text merging strategy"},{"location":"reference/configuration/#extract-parameters","title":"Extract Parameters","text":"Parameter Type Default Description <code>pages</code> <code>Sequence[int]</code> <code>None</code> Pages to extract (0-indexed). <code>None</code> = all pages <code>max_workers</code> <code>int</code> <code>1</code> Number of parallel workers <code>executor</code> <code>ExecutorType</code> <code>THREAD</code> Executor type for parallelism <code>table_options</code> <code>dict</code> <code>None</code> Tabula options for table extraction"},{"location":"reference/configuration/#table-extraction-options-tabula","title":"Table Extraction Options (Tabula)","text":"<p>Pass these options via the <code>table_options</code> parameter to enable table extraction.</p>"},{"location":"reference/configuration/#common-options","title":"Common Options","text":"Option Type Description <code>lattice</code> <code>bool</code> Use lattice mode for tables with visible cell borders <code>stream</code> <code>bool</code> Use stream mode for tables without visible borders <code>guess</code> <code>bool</code> Automatically guess table areas <code>multiple_tables</code> <code>bool</code> Extract multiple tables per page"},{"location":"reference/configuration/#area-options","title":"Area Options","text":"<p>Coordinates in <code>area</code> and <code>columns</code> follow the extractor's <code>output_unit</code> setting. The default unit is <code>POINTS</code> (1/72 inch).</p> Option Type Description <code>area</code> <code>tuple[float, float, float, float]</code> Extract area: (top, left, bottom, right) in output units <code>columns</code> <code>list[float]</code> X-coordinates for column splitting in output units"},{"location":"reference/configuration/#example","title":"Example","text":"<pre><code>from unifex import PdfExtractor, CoordinateUnit\n\nwith PdfExtractor(\"table.pdf\") as extractor:\n    # Lattice mode for bordered tables\n    result = extractor.extract(table_options={\"lattice\": True})\n\n    # Stream mode for borderless tables\n    result = extractor.extract(table_options={\"stream\": True})\n\n    # Extract from specific area (coordinates in points - the default)\n    result = extractor.extract(table_options={\n        \"area\": (100, 50, 400, 500),  # top, left, bottom, right in points\n        \"columns\": [100, 200, 350],   # column boundaries in points\n        \"lattice\": True,\n    })\n\n# Using different coordinate units\nwith PdfExtractor(\"table.pdf\", output_unit=CoordinateUnit.INCHES) as extractor:\n    # Coordinates are now in inches\n    result = extractor.extract(table_options={\n        \"area\": (1.0, 0.5, 5.0, 7.0),  # top, left, bottom, right in inches\n        \"columns\": [1.5, 3.0, 5.5],    # column boundaries in inches\n    })\n</code></pre>"},{"location":"reference/configuration/#environment-variables","title":"Environment Variables","text":""},{"location":"reference/configuration/#ocr-extractors","title":"OCR Extractors","text":"Variable Description Default <code>UNIFEX_AZURE_DI_ENDPOINT</code> Azure Document Intelligence endpoint URL - <code>UNIFEX_AZURE_DI_KEY</code> Azure Document Intelligence API key - <code>UNIFEX_AZURE_DI_MODEL</code> Azure model ID <code>prebuilt-read</code> <code>UNIFEX_GOOGLE_DOCAI_PROCESSOR_NAME</code> Google Document AI processor name - <code>UNIFEX_GOOGLE_DOCAI_CREDENTIALS_PATH</code> Path to Google service account JSON -"},{"location":"reference/configuration/#llm-providers","title":"LLM Providers","text":"Variable Description <code>OPENAI_API_KEY</code> OpenAI API key <code>ANTHROPIC_API_KEY</code> Anthropic API key <code>GOOGLE_API_KEY</code> Google AI API key <code>AZURE_OPENAI_API_KEY</code> Azure OpenAI API key <code>AZURE_OPENAI_ENDPOINT</code> Azure OpenAI endpoint URL <code>AZURE_OPENAI_API_VERSION</code> Azure OpenAI API version (default: <code>2024-02-15-preview</code>)"},{"location":"reference/configuration/#coordinate-units","title":"Coordinate Units","text":"<p>All extractors support the <code>output_unit</code> parameter to control the coordinate system of bounding boxes.</p> Unit Description Use Case <code>POINTS</code> 1/72 inch PDF native, resolution-independent <code>PIXELS</code> Pixels at specified DPI Image processing, display <code>INCHES</code> Imperial inches Print layout <code>NORMALIZED</code> 0-1 range relative to page ML models, relative positioning <p>Note</p> <p>PDF extractor doesn't support <code>PIXELS</code> output because PDFs don't have inherent DPI. OCR extractors use the <code>dpi</code> parameter for pixel conversions.</p>"},{"location":"reference/configuration/#dpi-settings","title":"DPI Settings","text":"<p>OCR extractors accept a <code>dpi</code> parameter that affects:</p> <ol> <li>PDF to image conversion - Higher DPI = larger images, better quality</li> <li>Coordinate conversion - Used when converting between PIXELS and other units</li> </ol> <p>Recommended values:</p> Use Case DPI Fast preview 72-100 Standard OCR 150-200 High quality 300+"},{"location":"reference/configuration/#parallel-processing","title":"Parallel Processing","text":""},{"location":"reference/configuration/#max_workers","title":"max_workers","text":"<p>Number of parallel workers for page extraction. Default is 1 (sequential).</p> <pre><code>result = extractor.extract(max_workers=4)\n</code></pre>"},{"location":"reference/configuration/#executor","title":"executor","text":"<p>Type of executor for parallel processing:</p> <ul> <li><code>ExecutorType.THREAD</code> (default) - Thread pool executor</li> <li><code>ExecutorType.PROCESS</code> - Process pool executor</li> </ul> <pre><code>from unifex import ExecutorType\n\nresult = extractor.extract(max_workers=4, executor=ExecutorType.PROCESS)\n</code></pre>"},{"location":"reference/extractors/","title":"Extractors Reference","text":""},{"location":"reference/extractors/#pdf-extractor","title":"PDF Extractor","text":""},{"location":"reference/extractors/#pdfextractor","title":"PdfExtractor","text":"<p>Native PDF text extraction using pypdfium2.</p>"},{"location":"reference/extractors/#unifex.pdf.PdfExtractor","title":"<code>unifex.pdf.PdfExtractor</code>","text":"<p>               Bases: <code>BaseExtractor</code></p> <p>Extract text and metadata from PDF files using pypdfium2.</p> Source code in <code>unifex/pdf/pdf.py</code> <pre><code>class PdfExtractor(BaseExtractor):\n    \"\"\"Extract text and metadata from PDF files using pypdfium2.\"\"\"\n\n    def __init__(\n        self,\n        path: Path | str,\n        output_unit: CoordinateUnit = CoordinateUnit.POINTS,\n        character_merger: CharacterMerger | None = None,\n    ) -&gt; None:\n        super().__init__(path, output_unit)\n        self._pdf = pdfium.PdfDocument(self.path)\n        self._merger = character_merger if character_merger is not None else BasicLineMerger()\n        self._lock = threading.Lock()\n\n    def get_page_count(self) -&gt; int:\n        return len(self._pdf)\n\n    def extract_page(\n        self,\n        page: int,\n        table_options: dict[str, Any] | None = None,\n    ) -&gt; PageExtractionResult:\n        \"\"\"Extract a single page by number (0-indexed).\n\n        Thread-safe: uses internal lock for parallel access.\n\n        Args:\n            page: Page number (0-indexed).\n            table_options: Optional dict of tabula options for table extraction.\n                If provided, tables will be extracted and added to Page.tables.\n                Common options: lattice, stream, columns, area, guess, multiple_tables.\n        \"\"\"\n        try:\n            with self._lock:\n                pdf_page = self._pdf[page]\n                width, height = pdf_page.get_size()\n                text_blocks = self._extract_text_blocks(pdf_page, height)\n\n            tables: list[Table] = []\n            if table_options is not None:\n                tables = self._extract_tables_for_page(page, table_options)\n\n            result_page = Page(\n                page=page,\n                width=width,\n                height=height,\n                texts=text_blocks,\n                tables=tables,\n            )\n            # Convert from native POINTS to output_unit\n            result_page = self._convert_page(result_page, CoordinateUnit.POINTS)\n            return PageExtractionResult(page=result_page, success=True)\n        except Exception as e:\n            return PageExtractionResult(\n                page=Page(page=page, width=0, height=0, texts=[]),\n                success=False,\n                error=str(e),\n            )\n\n    def get_extractor_metadata(self) -&gt; ExtractorMetadata:\n        metadata_dict = {}\n        try:\n            for key in [\"Title\", \"Author\", \"Creator\", \"Producer\", \"CreationDate\", \"ModDate\"]:\n                val = self._pdf.get_metadata_value(key)\n                if val:\n                    metadata_dict[key.lower()] = val\n        except (KeyError, ValueError, pdfium.PdfiumError) as e:\n            logger.warning(\"Failed to extract PDF metadata: %s\", e)\n\n        return ExtractorMetadata(\n            extractor_type=ExtractorType.PDF,\n            title=metadata_dict.get(\"title\"),\n            author=metadata_dict.get(\"author\"),\n            creator=metadata_dict.get(\"creator\"),\n            producer=metadata_dict.get(\"producer\"),\n            creation_date=metadata_dict.get(\"creationdate\"),\n            modification_date=metadata_dict.get(\"moddate\"),\n        )\n\n    def close(self) -&gt; None:\n        self._pdf.close()\n\n    def _extract_text_blocks(self, page: pdfium.PdfPage, page_height: float) -&gt; list[TextBlock]:\n        textpage = page.get_textpage()\n        char_count = textpage.count_chars()\n        if char_count == 0:\n            return []\n\n        # Batch text extraction (206x faster than per-char)\n        all_text = textpage.get_text_range(0, char_count)\n\n        # Check rotation support once, not per character\n        has_rotation = hasattr(textpage, \"get_char_rotation\")\n\n        chars: list[CharInfo] = []\n        for i in range(char_count):\n            bbox = textpage.get_charbox(i)\n            rotation = textpage.get_char_rotation(i) if has_rotation else 0\n            chars.append(CharInfo(char=all_text[i], bbox=bbox, rotation=rotation, index=i))\n\n        return self._merger.merge(chars, textpage, page_height)\n\n    def extract_tables(\n        self,\n        pages: Sequence[int] | None = None,\n        table_options: dict[str, Any] | None = None,\n    ) -&gt; list[Table]:\n        \"\"\"Extract tables from PDF pages using tabula.\n\n        Args:\n            pages: Sequence of page numbers to extract (0-indexed).\n                   If None, extracts from all pages.\n            table_options: Dict of tabula options. Common options:\n                - lattice: bool - Use lattice mode (tables with cell borders)\n                - stream: bool - Use stream mode (tables without borders)\n                - columns: list[float] - Column x-coordinates for splitting\n                - area: tuple[float, float, float, float] - (top, left, bottom, right)\n                - guess: bool - Guess table areas automatically\n                - multiple_tables: bool - Extract multiple tables per page\n                - pandas_options: dict - Options for pandas\n\n        Returns:\n            List of Table objects with page field indicating source page.\n        \"\"\"\n        if pages is None:\n            pages = range(self.get_page_count())\n\n        options = table_options or {}\n        all_tables: list[Table] = []\n\n        for page_num in pages:\n            page_tables = self._extract_tables_for_page(page_num, options)\n            all_tables.extend(page_tables)\n\n        return all_tables\n\n    def _extract_tables_for_page(\n        self,\n        page: int,\n        options: dict[str, Any],\n    ) -&gt; list[Table]:\n        \"\"\"Extract tables from a single page using tabula.\n\n        Args:\n            page: Page number (0-indexed).\n            options: Tabula options dict.\n\n        Returns:\n            List of Table objects for this page.\n        \"\"\"\n        try:\n            import tabula\n        except ImportError as e:\n            raise ImportError(\n                \"tabula-py is required for table extraction. \"\n                \"Install with: pip install 'unifex[tables]'\"\n            ) from e\n\n        tabula_opts = self._build_tabula_options(page, options)\n        dfs = tabula.read_pdf(str(self.path), **tabula_opts)\n\n        return [self._dataframe_to_table(df, page) for df in dfs if not df.empty]\n\n    def _build_tabula_options(self, page: int, options: dict[str, Any]) -&gt; dict[str, Any]:\n        \"\"\"Build tabula options dict from user options.\"\"\"\n        # Tabula uses 1-indexed pages\n        tabula_opts: dict[str, Any] = {\n            \"pages\": page + 1,\n            \"multiple_tables\": options.get(\"multiple_tables\", True),\n            \"guess\": options.get(\"guess\", True),\n        }\n\n        # Copy optional settings\n        for key in (\"lattice\", \"stream\", \"columns\", \"area\", \"pandas_options\"):\n            if options.get(key):\n                tabula_opts[key] = options[key]\n\n        return tabula_opts\n\n    def _dataframe_to_table(self, df: Any, page: int) -&gt; Table:\n        \"\"\"Convert a pandas DataFrame to a Table model.\"\"\"\n        cells: list[TableCell] = []\n        row_count = len(df)\n        col_count = len(df.columns)\n\n        # Add header row (column names)\n        for col_idx, col_name in enumerate(df.columns):\n            cell_text = str(col_name) if col_name is not None else \"\"\n            cells.append(TableCell(text=cell_text, row=0, col=col_idx))\n\n        # Add data rows\n        for row_idx, row in enumerate(df.itertuples(index=False), start=1):\n            for col_idx, value in enumerate(row):\n                cell_text = str(value) if value is not None and str(value) != \"nan\" else \"\"\n                cells.append(TableCell(text=cell_text, row=row_idx, col=col_idx))\n\n        return Table(\n            page=page,\n            cells=cells,\n            row_count=row_count + 1,  # +1 for header row\n            col_count=col_count,\n        )\n</code></pre>"},{"location":"reference/extractors/#unifex.pdf.PdfExtractor.extract_page","title":"<code>extract_page(page, table_options=None)</code>","text":"<p>Extract a single page by number (0-indexed).</p> <p>Thread-safe: uses internal lock for parallel access.</p> <p>Parameters:</p> Name Type Description Default <code>page</code> <code>int</code> <p>Page number (0-indexed).</p> required <code>table_options</code> <code>dict[str, Any] | None</code> <p>Optional dict of tabula options for table extraction. If provided, tables will be extracted and added to Page.tables. Common options: lattice, stream, columns, area, guess, multiple_tables.</p> <code>None</code> Source code in <code>unifex/pdf/pdf.py</code> <pre><code>def extract_page(\n    self,\n    page: int,\n    table_options: dict[str, Any] | None = None,\n) -&gt; PageExtractionResult:\n    \"\"\"Extract a single page by number (0-indexed).\n\n    Thread-safe: uses internal lock for parallel access.\n\n    Args:\n        page: Page number (0-indexed).\n        table_options: Optional dict of tabula options for table extraction.\n            If provided, tables will be extracted and added to Page.tables.\n            Common options: lattice, stream, columns, area, guess, multiple_tables.\n    \"\"\"\n    try:\n        with self._lock:\n            pdf_page = self._pdf[page]\n            width, height = pdf_page.get_size()\n            text_blocks = self._extract_text_blocks(pdf_page, height)\n\n        tables: list[Table] = []\n        if table_options is not None:\n            tables = self._extract_tables_for_page(page, table_options)\n\n        result_page = Page(\n            page=page,\n            width=width,\n            height=height,\n            texts=text_blocks,\n            tables=tables,\n        )\n        # Convert from native POINTS to output_unit\n        result_page = self._convert_page(result_page, CoordinateUnit.POINTS)\n        return PageExtractionResult(page=result_page, success=True)\n    except Exception as e:\n        return PageExtractionResult(\n            page=Page(page=page, width=0, height=0, texts=[]),\n            success=False,\n            error=str(e),\n        )\n</code></pre>"},{"location":"reference/extractors/#unifex.pdf.PdfExtractor.extract_tables","title":"<code>extract_tables(pages=None, table_options=None)</code>","text":"<p>Extract tables from PDF pages using tabula.</p> <p>Parameters:</p> Name Type Description Default <code>pages</code> <code>Sequence[int] | None</code> <p>Sequence of page numbers to extract (0-indexed).    If None, extracts from all pages.</p> <code>None</code> <code>table_options</code> <code>dict[str, Any] | None</code> <p>Dict of tabula options. Common options: - lattice: bool - Use lattice mode (tables with cell borders) - stream: bool - Use stream mode (tables without borders) - columns: list[float] - Column x-coordinates for splitting - area: tuple[float, float, float, float] - (top, left, bottom, right) - guess: bool - Guess table areas automatically - multiple_tables: bool - Extract multiple tables per page - pandas_options: dict - Options for pandas</p> <code>None</code> <p>Returns:</p> Type Description <code>list[Table]</code> <p>List of Table objects with page field indicating source page.</p> Source code in <code>unifex/pdf/pdf.py</code> <pre><code>def extract_tables(\n    self,\n    pages: Sequence[int] | None = None,\n    table_options: dict[str, Any] | None = None,\n) -&gt; list[Table]:\n    \"\"\"Extract tables from PDF pages using tabula.\n\n    Args:\n        pages: Sequence of page numbers to extract (0-indexed).\n               If None, extracts from all pages.\n        table_options: Dict of tabula options. Common options:\n            - lattice: bool - Use lattice mode (tables with cell borders)\n            - stream: bool - Use stream mode (tables without borders)\n            - columns: list[float] - Column x-coordinates for splitting\n            - area: tuple[float, float, float, float] - (top, left, bottom, right)\n            - guess: bool - Guess table areas automatically\n            - multiple_tables: bool - Extract multiple tables per page\n            - pandas_options: dict - Options for pandas\n\n    Returns:\n        List of Table objects with page field indicating source page.\n    \"\"\"\n    if pages is None:\n        pages = range(self.get_page_count())\n\n    options = table_options or {}\n    all_tables: list[Table] = []\n\n    for page_num in pages:\n        page_tables = self._extract_tables_for_page(page_num, options)\n        all_tables.extend(page_tables)\n\n    return all_tables\n</code></pre>"},{"location":"reference/extractors/#local-ocr-extractors","title":"Local OCR Extractors","text":""},{"location":"reference/extractors/#easyocrextractor","title":"EasyOcrExtractor","text":"<p>OCR using EasyOCR library.</p>"},{"location":"reference/extractors/#unifex.ocr.extractors.easy_ocr.EasyOcrExtractor","title":"<code>unifex.ocr.extractors.easy_ocr.EasyOcrExtractor</code>","text":"<p>               Bases: <code>BaseExtractor</code></p> <p>Extract text from images or PDFs using EasyOCR.</p> <p>Composes ImageLoader for image handling, EasyOCR for OCR processing, and EasyOCRAdapter for result conversion.</p> Source code in <code>unifex/ocr/extractors/easy_ocr.py</code> <pre><code>class EasyOcrExtractor(BaseExtractor):\n    \"\"\"Extract text from images or PDFs using EasyOCR.\n\n    Composes ImageLoader for image handling, EasyOCR for OCR processing,\n    and EasyOCRAdapter for result conversion.\n    \"\"\"\n\n    def __init__(\n        self,\n        path: Path | str,\n        languages: list[str] | None = None,\n        gpu: bool = False,\n        dpi: int = 200,\n        output_unit: CoordinateUnit = CoordinateUnit.POINTS,\n    ) -&gt; None:\n        \"\"\"Initialize EasyOCR extractor.\n\n        Args:\n            path: Path to the image or PDF file (Path object or string).\n            languages: List of language codes for OCR. Defaults to [\"en\"].\n            gpu: Whether to use GPU acceleration.\n            dpi: DPI for PDF-to-image conversion. Default 200.\n            output_unit: Coordinate unit for output. Default POINTS.\n        \"\"\"\n        _check_easyocr_installed()\n        super().__init__(path, output_unit)\n        self.languages = languages or [\"en\"]\n        self.gpu = gpu\n        self.dpi = dpi\n\n        # Compose components\n        self._images = ImageLoader(self.path, dpi)\n        self._adapter = EasyOCRAdapter()\n\n    def get_page_count(self) -&gt; int:\n        \"\"\"Return number of pages/images loaded.\"\"\"\n        return self._images.page_count\n\n    def extract_page(self, page: int) -&gt; PageExtractionResult:\n        \"\"\"Extract text from a single image/page.\"\"\"\n        import numpy as np\n\n        try:\n            img = self._images.get_page(page)\n            width, height = img.size\n\n            # Run OCR pipeline\n            reader = get_reader(self.languages, self.gpu)\n            results = reader.readtext(np.array(img))\n            text_blocks = self._adapter.convert_result(results)\n\n            result_page = Page(\n                page=page,\n                width=float(width),\n                height=float(height),\n                texts=text_blocks,\n            )\n\n            # Convert from native PIXELS to output_unit\n            result_page = self._convert_page(result_page, CoordinateUnit.PIXELS, self.dpi)\n            return PageExtractionResult(page=result_page, success=True)\n\n        except Exception as e:\n            logger.warning(\"Failed to extract page %d: %s\", page, e)\n            return PageExtractionResult(\n                page=Page(page=page, width=0, height=0, texts=[]),\n                success=False,\n                error=str(e),\n            )\n\n    def get_extractor_metadata(self) -&gt; ExtractorMetadata:\n        \"\"\"Return extractor metadata.\"\"\"\n        extra = {\"ocr_engine\": \"easyocr\", \"languages\": self.languages}\n        if self._images.is_pdf:\n            extra[\"dpi\"] = self.dpi\n        return ExtractorMetadata(\n            extractor_type=ExtractorType.EASYOCR,\n            extra=extra,\n        )\n\n    def close(self) -&gt; None:\n        \"\"\"Release resources.\"\"\"\n        self._images.close()\n</code></pre>"},{"location":"reference/extractors/#unifex.ocr.extractors.easy_ocr.EasyOcrExtractor.__init__","title":"<code>__init__(path, languages=None, gpu=False, dpi=200, output_unit=CoordinateUnit.POINTS)</code>","text":"<p>Initialize EasyOCR extractor.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path | str</code> <p>Path to the image or PDF file (Path object or string).</p> required <code>languages</code> <code>list[str] | None</code> <p>List of language codes for OCR. Defaults to [\"en\"].</p> <code>None</code> <code>gpu</code> <code>bool</code> <p>Whether to use GPU acceleration.</p> <code>False</code> <code>dpi</code> <code>int</code> <p>DPI for PDF-to-image conversion. Default 200.</p> <code>200</code> <code>output_unit</code> <code>CoordinateUnit</code> <p>Coordinate unit for output. Default POINTS.</p> <code>POINTS</code> Source code in <code>unifex/ocr/extractors/easy_ocr.py</code> <pre><code>def __init__(\n    self,\n    path: Path | str,\n    languages: list[str] | None = None,\n    gpu: bool = False,\n    dpi: int = 200,\n    output_unit: CoordinateUnit = CoordinateUnit.POINTS,\n) -&gt; None:\n    \"\"\"Initialize EasyOCR extractor.\n\n    Args:\n        path: Path to the image or PDF file (Path object or string).\n        languages: List of language codes for OCR. Defaults to [\"en\"].\n        gpu: Whether to use GPU acceleration.\n        dpi: DPI for PDF-to-image conversion. Default 200.\n        output_unit: Coordinate unit for output. Default POINTS.\n    \"\"\"\n    _check_easyocr_installed()\n    super().__init__(path, output_unit)\n    self.languages = languages or [\"en\"]\n    self.gpu = gpu\n    self.dpi = dpi\n\n    # Compose components\n    self._images = ImageLoader(self.path, dpi)\n    self._adapter = EasyOCRAdapter()\n</code></pre>"},{"location":"reference/extractors/#unifex.ocr.extractors.easy_ocr.EasyOcrExtractor.get_page_count","title":"<code>get_page_count()</code>","text":"<p>Return number of pages/images loaded.</p> Source code in <code>unifex/ocr/extractors/easy_ocr.py</code> <pre><code>def get_page_count(self) -&gt; int:\n    \"\"\"Return number of pages/images loaded.\"\"\"\n    return self._images.page_count\n</code></pre>"},{"location":"reference/extractors/#unifex.ocr.extractors.easy_ocr.EasyOcrExtractor.extract_page","title":"<code>extract_page(page)</code>","text":"<p>Extract text from a single image/page.</p> Source code in <code>unifex/ocr/extractors/easy_ocr.py</code> <pre><code>def extract_page(self, page: int) -&gt; PageExtractionResult:\n    \"\"\"Extract text from a single image/page.\"\"\"\n    import numpy as np\n\n    try:\n        img = self._images.get_page(page)\n        width, height = img.size\n\n        # Run OCR pipeline\n        reader = get_reader(self.languages, self.gpu)\n        results = reader.readtext(np.array(img))\n        text_blocks = self._adapter.convert_result(results)\n\n        result_page = Page(\n            page=page,\n            width=float(width),\n            height=float(height),\n            texts=text_blocks,\n        )\n\n        # Convert from native PIXELS to output_unit\n        result_page = self._convert_page(result_page, CoordinateUnit.PIXELS, self.dpi)\n        return PageExtractionResult(page=result_page, success=True)\n\n    except Exception as e:\n        logger.warning(\"Failed to extract page %d: %s\", page, e)\n        return PageExtractionResult(\n            page=Page(page=page, width=0, height=0, texts=[]),\n            success=False,\n            error=str(e),\n        )\n</code></pre>"},{"location":"reference/extractors/#unifex.ocr.extractors.easy_ocr.EasyOcrExtractor.get_extractor_metadata","title":"<code>get_extractor_metadata()</code>","text":"<p>Return extractor metadata.</p> Source code in <code>unifex/ocr/extractors/easy_ocr.py</code> <pre><code>def get_extractor_metadata(self) -&gt; ExtractorMetadata:\n    \"\"\"Return extractor metadata.\"\"\"\n    extra = {\"ocr_engine\": \"easyocr\", \"languages\": self.languages}\n    if self._images.is_pdf:\n        extra[\"dpi\"] = self.dpi\n    return ExtractorMetadata(\n        extractor_type=ExtractorType.EASYOCR,\n        extra=extra,\n    )\n</code></pre>"},{"location":"reference/extractors/#unifex.ocr.extractors.easy_ocr.EasyOcrExtractor.close","title":"<code>close()</code>","text":"<p>Release resources.</p> Source code in <code>unifex/ocr/extractors/easy_ocr.py</code> <pre><code>def close(self) -&gt; None:\n    \"\"\"Release resources.\"\"\"\n    self._images.close()\n</code></pre>"},{"location":"reference/extractors/#tesseractocrextractor","title":"TesseractOcrExtractor","text":"<p>OCR using Tesseract.</p>"},{"location":"reference/extractors/#unifex.ocr.extractors.tesseract_ocr.TesseractOcrExtractor","title":"<code>unifex.ocr.extractors.tesseract_ocr.TesseractOcrExtractor</code>","text":"<p>               Bases: <code>BaseExtractor</code></p> <p>Extract text from images or PDFs using Tesseract OCR.</p> <p>Composes ImageLoader for image handling, Tesseract for OCR processing, and TesseractAdapter for result conversion.</p> Source code in <code>unifex/ocr/extractors/tesseract_ocr.py</code> <pre><code>class TesseractOcrExtractor(BaseExtractor):\n    \"\"\"Extract text from images or PDFs using Tesseract OCR.\n\n    Composes ImageLoader for image handling, Tesseract for OCR processing,\n    and TesseractAdapter for result conversion.\n    \"\"\"\n\n    def __init__(\n        self,\n        path: Path | str,\n        languages: list[str] | None = None,\n        dpi: int = 200,\n        output_unit: CoordinateUnit = CoordinateUnit.POINTS,\n    ) -&gt; None:\n        \"\"\"Initialize Tesseract OCR extractor.\n\n        Args:\n            path: Path to the image or PDF file (Path object or string).\n            languages: List of 2-letter ISO 639-1 language codes (e.g., [\"en\", \"fr\"]).\n                       Defaults to [\"en\"]. Codes are converted to Tesseract format internally.\n            dpi: DPI for PDF-to-image conversion. Default 200.\n            output_unit: Coordinate unit for output. Default POINTS.\n        \"\"\"\n        _check_pytesseract_installed()\n        super().__init__(path, output_unit)\n        input_languages = languages or [\"en\"]\n        # Store original 2-letter codes for metadata\n        self.languages = input_languages\n        # Convert to Tesseract format for internal use\n        self._tesseract_languages = [_convert_lang_code(lang) for lang in input_languages]\n        self.dpi = dpi\n\n        # Compose components\n        self._images = ImageLoader(self.path, dpi)\n        self._adapter = TesseractAdapter()\n\n    def get_page_count(self) -&gt; int:\n        \"\"\"Return number of pages/images loaded.\"\"\"\n        return self._images.page_count\n\n    def extract_page(self, page: int) -&gt; PageExtractionResult:\n        \"\"\"Extract text from a single image/page.\"\"\"\n        import pytesseract\n\n        try:\n            img = self._images.get_page(page)\n            width, height = img.size\n\n            # Run OCR pipeline\n            lang_str = \"+\".join(self._tesseract_languages)\n            data = pytesseract.image_to_data(\n                img, lang=lang_str, output_type=pytesseract.Output.DICT\n            )\n            text_blocks = self._adapter.convert_result(data)\n\n            result_page = Page(\n                page=page,\n                width=float(width),\n                height=float(height),\n                texts=text_blocks,\n            )\n\n            # Convert from native PIXELS to output_unit\n            result_page = self._convert_page(result_page, CoordinateUnit.PIXELS, self.dpi)\n            return PageExtractionResult(page=result_page, success=True)\n\n        except Exception as e:\n            logger.warning(\"Failed to extract page %d: %s\", page, e)\n            return PageExtractionResult(\n                page=Page(page=page, width=0, height=0, texts=[]),\n                success=False,\n                error=str(e),\n            )\n\n    def get_extractor_metadata(self) -&gt; ExtractorMetadata:\n        \"\"\"Return extractor metadata.\"\"\"\n        extra = {\"ocr_engine\": \"tesseract\", \"languages\": self.languages}\n        if self._images.is_pdf:\n            extra[\"dpi\"] = self.dpi\n        return ExtractorMetadata(\n            extractor_type=ExtractorType.TESSERACT,\n            extra=extra,\n        )\n\n    def close(self) -&gt; None:\n        \"\"\"Release resources.\"\"\"\n        self._images.close()\n</code></pre>"},{"location":"reference/extractors/#unifex.ocr.extractors.tesseract_ocr.TesseractOcrExtractor.__init__","title":"<code>__init__(path, languages=None, dpi=200, output_unit=CoordinateUnit.POINTS)</code>","text":"<p>Initialize Tesseract OCR extractor.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path | str</code> <p>Path to the image or PDF file (Path object or string).</p> required <code>languages</code> <code>list[str] | None</code> <p>List of 2-letter ISO 639-1 language codes (e.g., [\"en\", \"fr\"]).        Defaults to [\"en\"]. Codes are converted to Tesseract format internally.</p> <code>None</code> <code>dpi</code> <code>int</code> <p>DPI for PDF-to-image conversion. Default 200.</p> <code>200</code> <code>output_unit</code> <code>CoordinateUnit</code> <p>Coordinate unit for output. Default POINTS.</p> <code>POINTS</code> Source code in <code>unifex/ocr/extractors/tesseract_ocr.py</code> <pre><code>def __init__(\n    self,\n    path: Path | str,\n    languages: list[str] | None = None,\n    dpi: int = 200,\n    output_unit: CoordinateUnit = CoordinateUnit.POINTS,\n) -&gt; None:\n    \"\"\"Initialize Tesseract OCR extractor.\n\n    Args:\n        path: Path to the image or PDF file (Path object or string).\n        languages: List of 2-letter ISO 639-1 language codes (e.g., [\"en\", \"fr\"]).\n                   Defaults to [\"en\"]. Codes are converted to Tesseract format internally.\n        dpi: DPI for PDF-to-image conversion. Default 200.\n        output_unit: Coordinate unit for output. Default POINTS.\n    \"\"\"\n    _check_pytesseract_installed()\n    super().__init__(path, output_unit)\n    input_languages = languages or [\"en\"]\n    # Store original 2-letter codes for metadata\n    self.languages = input_languages\n    # Convert to Tesseract format for internal use\n    self._tesseract_languages = [_convert_lang_code(lang) for lang in input_languages]\n    self.dpi = dpi\n\n    # Compose components\n    self._images = ImageLoader(self.path, dpi)\n    self._adapter = TesseractAdapter()\n</code></pre>"},{"location":"reference/extractors/#unifex.ocr.extractors.tesseract_ocr.TesseractOcrExtractor.get_page_count","title":"<code>get_page_count()</code>","text":"<p>Return number of pages/images loaded.</p> Source code in <code>unifex/ocr/extractors/tesseract_ocr.py</code> <pre><code>def get_page_count(self) -&gt; int:\n    \"\"\"Return number of pages/images loaded.\"\"\"\n    return self._images.page_count\n</code></pre>"},{"location":"reference/extractors/#unifex.ocr.extractors.tesseract_ocr.TesseractOcrExtractor.extract_page","title":"<code>extract_page(page)</code>","text":"<p>Extract text from a single image/page.</p> Source code in <code>unifex/ocr/extractors/tesseract_ocr.py</code> <pre><code>def extract_page(self, page: int) -&gt; PageExtractionResult:\n    \"\"\"Extract text from a single image/page.\"\"\"\n    import pytesseract\n\n    try:\n        img = self._images.get_page(page)\n        width, height = img.size\n\n        # Run OCR pipeline\n        lang_str = \"+\".join(self._tesseract_languages)\n        data = pytesseract.image_to_data(\n            img, lang=lang_str, output_type=pytesseract.Output.DICT\n        )\n        text_blocks = self._adapter.convert_result(data)\n\n        result_page = Page(\n            page=page,\n            width=float(width),\n            height=float(height),\n            texts=text_blocks,\n        )\n\n        # Convert from native PIXELS to output_unit\n        result_page = self._convert_page(result_page, CoordinateUnit.PIXELS, self.dpi)\n        return PageExtractionResult(page=result_page, success=True)\n\n    except Exception as e:\n        logger.warning(\"Failed to extract page %d: %s\", page, e)\n        return PageExtractionResult(\n            page=Page(page=page, width=0, height=0, texts=[]),\n            success=False,\n            error=str(e),\n        )\n</code></pre>"},{"location":"reference/extractors/#unifex.ocr.extractors.tesseract_ocr.TesseractOcrExtractor.get_extractor_metadata","title":"<code>get_extractor_metadata()</code>","text":"<p>Return extractor metadata.</p> Source code in <code>unifex/ocr/extractors/tesseract_ocr.py</code> <pre><code>def get_extractor_metadata(self) -&gt; ExtractorMetadata:\n    \"\"\"Return extractor metadata.\"\"\"\n    extra = {\"ocr_engine\": \"tesseract\", \"languages\": self.languages}\n    if self._images.is_pdf:\n        extra[\"dpi\"] = self.dpi\n    return ExtractorMetadata(\n        extractor_type=ExtractorType.TESSERACT,\n        extra=extra,\n    )\n</code></pre>"},{"location":"reference/extractors/#unifex.ocr.extractors.tesseract_ocr.TesseractOcrExtractor.close","title":"<code>close()</code>","text":"<p>Release resources.</p> Source code in <code>unifex/ocr/extractors/tesseract_ocr.py</code> <pre><code>def close(self) -&gt; None:\n    \"\"\"Release resources.\"\"\"\n    self._images.close()\n</code></pre>"},{"location":"reference/extractors/#paddleocrextractor","title":"PaddleOcrExtractor","text":"<p>OCR using PaddleOCR.</p>"},{"location":"reference/extractors/#unifex.ocr.extractors.paddle_ocr.PaddleOcrExtractor","title":"<code>unifex.ocr.extractors.paddle_ocr.PaddleOcrExtractor</code>","text":"<p>               Bases: <code>BaseExtractor</code></p> <p>Extract text from images or PDFs using PaddleOCR.</p> <p>Composes ImageLoader for image handling, PaddleOCR for OCR, and PaddleOCRAdapter for result conversion.</p> <p>PaddleOCR model is loaded lazily on first extraction and cached globally.</p> Source code in <code>unifex/ocr/extractors/paddle_ocr.py</code> <pre><code>class PaddleOcrExtractor(BaseExtractor):\n    \"\"\"Extract text from images or PDFs using PaddleOCR.\n\n    Composes ImageLoader for image handling, PaddleOCR for OCR,\n    and PaddleOCRAdapter for result conversion.\n\n    PaddleOCR model is loaded lazily on first extraction and cached globally.\n    \"\"\"\n\n    def __init__(\n        self,\n        path: Path | str,\n        lang: str = \"en\",\n        use_gpu: bool = False,\n        dpi: int = 200,\n        output_unit: CoordinateUnit = CoordinateUnit.POINTS,\n    ) -&gt; None:\n        \"\"\"Initialize PaddleOCR extractor.\n\n        Args:\n            path: Path to the image or PDF file (Path object or string).\n            lang: Language code for OCR. Common values:\n                  - \"en\" for English\n                  - \"ch\" for Chinese\n                  - \"fr\" for French\n                  - \"german\" for German\n                  - \"japan\" for Japanese\n                  - \"korean\" for Korean\n                  See PaddleOCR docs for full list.\n            use_gpu: Whether to use GPU acceleration.\n            dpi: DPI for PDF-to-image conversion. Default 200.\n            output_unit: Coordinate unit for output. Default POINTS.\n        \"\"\"\n        _check_paddleocr_installed()\n        super().__init__(path, output_unit)\n        self.lang = lang\n        self.use_gpu = use_gpu\n        self.dpi = dpi\n\n        # Compose components (lazy - OCR loaded on first use)\n        self._images = ImageLoader(self.path, dpi)\n        self._adapter = PaddleOCRAdapter()\n\n    def get_page_count(self) -&gt; int:\n        \"\"\"Return number of pages/images loaded.\"\"\"\n        return self._images.page_count\n\n    def extract_page(self, page: int) -&gt; PageExtractionResult:\n        \"\"\"Extract text from a single image/page.\"\"\"\n        import numpy as np\n\n        try:\n            img = self._images.get_page(page)\n            width, height = img.size\n\n            # Run OCR pipeline (lazy load model)\n            ocr = get_paddle_ocr(self.lang, self.use_gpu)\n            img_array = np.array(img)\n\n            # Use version-specific API\n            major_version = _get_paddle_major_version()\n            if major_version &gt;= PADDLEOCR_V3_MAJOR:\n                result = ocr.predict(img_array)\n            else:\n                result = ocr.ocr(img_array, cls=True)\n\n            text_blocks = self._adapter.convert_result(result, major_version)\n\n            result_page = Page(\n                page=page,\n                width=float(width),\n                height=float(height),\n                texts=text_blocks,\n            )\n\n            # Convert from native PIXELS to output_unit\n            result_page = self._convert_page(result_page, CoordinateUnit.PIXELS, self.dpi)\n            return PageExtractionResult(page=result_page, success=True)\n\n        except Exception as e:\n            logger.warning(\"Failed to extract page %d: %s\", page, e)\n            return PageExtractionResult(\n                page=Page(page=page, width=0, height=0, texts=[]),\n                success=False,\n                error=str(e),\n            )\n\n    def extract_tables(\n        self,\n        pages: list[int] | None = None,\n    ) -&gt; list[Table]:\n        \"\"\"Extract tables from document using PPStructure.\n\n        Args:\n            pages: List of page numbers to extract (0-indexed).\n                   If None, extracts from all pages.\n\n        Returns:\n            List of Table objects with page field indicating source page.\n        \"\"\"\n        import numpy as np\n\n        if pages is None:\n            pages = list(range(self.get_page_count()))\n\n        all_tables: list[Table] = []\n        engine = get_ppstructure(self.lang, self.use_gpu)\n\n        for page_num in pages:\n            try:\n                img = self._images.get_page(page_num)\n                img_array = np.array(img)\n\n                # PPStructure returns list of layout elements\n                result = engine(img_array)\n\n                for element in result:\n                    if element.get(\"type\") == \"table\":\n                        table = self._adapter.convert_table_result(element, page=page_num)\n                        all_tables.append(table)\n\n            except Exception as e:\n                logger.warning(\"Failed to extract tables from page %d: %s\", page_num, e)\n\n        return all_tables\n\n    def get_extractor_metadata(self) -&gt; ExtractorMetadata:\n        \"\"\"Return extractor metadata.\"\"\"\n        extra = {\"ocr_engine\": \"paddleocr\", \"languages\": self.lang}\n        if self._images.is_pdf:\n            extra[\"dpi\"] = self.dpi\n        return ExtractorMetadata(\n            extractor_type=ExtractorType.PADDLE,\n            extra=extra,\n        )\n\n    def close(self) -&gt; None:\n        \"\"\"Release resources.\"\"\"\n        self._images.close()\n</code></pre>"},{"location":"reference/extractors/#unifex.ocr.extractors.paddle_ocr.PaddleOcrExtractor.__init__","title":"<code>__init__(path, lang='en', use_gpu=False, dpi=200, output_unit=CoordinateUnit.POINTS)</code>","text":"<p>Initialize PaddleOCR extractor.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path | str</code> <p>Path to the image or PDF file (Path object or string).</p> required <code>lang</code> <code>str</code> <p>Language code for OCR. Common values:   - \"en\" for English   - \"ch\" for Chinese   - \"fr\" for French   - \"german\" for German   - \"japan\" for Japanese   - \"korean\" for Korean   See PaddleOCR docs for full list.</p> <code>'en'</code> <code>use_gpu</code> <code>bool</code> <p>Whether to use GPU acceleration.</p> <code>False</code> <code>dpi</code> <code>int</code> <p>DPI for PDF-to-image conversion. Default 200.</p> <code>200</code> <code>output_unit</code> <code>CoordinateUnit</code> <p>Coordinate unit for output. Default POINTS.</p> <code>POINTS</code> Source code in <code>unifex/ocr/extractors/paddle_ocr.py</code> <pre><code>def __init__(\n    self,\n    path: Path | str,\n    lang: str = \"en\",\n    use_gpu: bool = False,\n    dpi: int = 200,\n    output_unit: CoordinateUnit = CoordinateUnit.POINTS,\n) -&gt; None:\n    \"\"\"Initialize PaddleOCR extractor.\n\n    Args:\n        path: Path to the image or PDF file (Path object or string).\n        lang: Language code for OCR. Common values:\n              - \"en\" for English\n              - \"ch\" for Chinese\n              - \"fr\" for French\n              - \"german\" for German\n              - \"japan\" for Japanese\n              - \"korean\" for Korean\n              See PaddleOCR docs for full list.\n        use_gpu: Whether to use GPU acceleration.\n        dpi: DPI for PDF-to-image conversion. Default 200.\n        output_unit: Coordinate unit for output. Default POINTS.\n    \"\"\"\n    _check_paddleocr_installed()\n    super().__init__(path, output_unit)\n    self.lang = lang\n    self.use_gpu = use_gpu\n    self.dpi = dpi\n\n    # Compose components (lazy - OCR loaded on first use)\n    self._images = ImageLoader(self.path, dpi)\n    self._adapter = PaddleOCRAdapter()\n</code></pre>"},{"location":"reference/extractors/#unifex.ocr.extractors.paddle_ocr.PaddleOcrExtractor.get_page_count","title":"<code>get_page_count()</code>","text":"<p>Return number of pages/images loaded.</p> Source code in <code>unifex/ocr/extractors/paddle_ocr.py</code> <pre><code>def get_page_count(self) -&gt; int:\n    \"\"\"Return number of pages/images loaded.\"\"\"\n    return self._images.page_count\n</code></pre>"},{"location":"reference/extractors/#unifex.ocr.extractors.paddle_ocr.PaddleOcrExtractor.extract_page","title":"<code>extract_page(page)</code>","text":"<p>Extract text from a single image/page.</p> Source code in <code>unifex/ocr/extractors/paddle_ocr.py</code> <pre><code>def extract_page(self, page: int) -&gt; PageExtractionResult:\n    \"\"\"Extract text from a single image/page.\"\"\"\n    import numpy as np\n\n    try:\n        img = self._images.get_page(page)\n        width, height = img.size\n\n        # Run OCR pipeline (lazy load model)\n        ocr = get_paddle_ocr(self.lang, self.use_gpu)\n        img_array = np.array(img)\n\n        # Use version-specific API\n        major_version = _get_paddle_major_version()\n        if major_version &gt;= PADDLEOCR_V3_MAJOR:\n            result = ocr.predict(img_array)\n        else:\n            result = ocr.ocr(img_array, cls=True)\n\n        text_blocks = self._adapter.convert_result(result, major_version)\n\n        result_page = Page(\n            page=page,\n            width=float(width),\n            height=float(height),\n            texts=text_blocks,\n        )\n\n        # Convert from native PIXELS to output_unit\n        result_page = self._convert_page(result_page, CoordinateUnit.PIXELS, self.dpi)\n        return PageExtractionResult(page=result_page, success=True)\n\n    except Exception as e:\n        logger.warning(\"Failed to extract page %d: %s\", page, e)\n        return PageExtractionResult(\n            page=Page(page=page, width=0, height=0, texts=[]),\n            success=False,\n            error=str(e),\n        )\n</code></pre>"},{"location":"reference/extractors/#unifex.ocr.extractors.paddle_ocr.PaddleOcrExtractor.extract_tables","title":"<code>extract_tables(pages=None)</code>","text":"<p>Extract tables from document using PPStructure.</p> <p>Parameters:</p> Name Type Description Default <code>pages</code> <code>list[int] | None</code> <p>List of page numbers to extract (0-indexed).    If None, extracts from all pages.</p> <code>None</code> <p>Returns:</p> Type Description <code>list[Table]</code> <p>List of Table objects with page field indicating source page.</p> Source code in <code>unifex/ocr/extractors/paddle_ocr.py</code> <pre><code>def extract_tables(\n    self,\n    pages: list[int] | None = None,\n) -&gt; list[Table]:\n    \"\"\"Extract tables from document using PPStructure.\n\n    Args:\n        pages: List of page numbers to extract (0-indexed).\n               If None, extracts from all pages.\n\n    Returns:\n        List of Table objects with page field indicating source page.\n    \"\"\"\n    import numpy as np\n\n    if pages is None:\n        pages = list(range(self.get_page_count()))\n\n    all_tables: list[Table] = []\n    engine = get_ppstructure(self.lang, self.use_gpu)\n\n    for page_num in pages:\n        try:\n            img = self._images.get_page(page_num)\n            img_array = np.array(img)\n\n            # PPStructure returns list of layout elements\n            result = engine(img_array)\n\n            for element in result:\n                if element.get(\"type\") == \"table\":\n                    table = self._adapter.convert_table_result(element, page=page_num)\n                    all_tables.append(table)\n\n        except Exception as e:\n            logger.warning(\"Failed to extract tables from page %d: %s\", page_num, e)\n\n    return all_tables\n</code></pre>"},{"location":"reference/extractors/#unifex.ocr.extractors.paddle_ocr.PaddleOcrExtractor.get_extractor_metadata","title":"<code>get_extractor_metadata()</code>","text":"<p>Return extractor metadata.</p> Source code in <code>unifex/ocr/extractors/paddle_ocr.py</code> <pre><code>def get_extractor_metadata(self) -&gt; ExtractorMetadata:\n    \"\"\"Return extractor metadata.\"\"\"\n    extra = {\"ocr_engine\": \"paddleocr\", \"languages\": self.lang}\n    if self._images.is_pdf:\n        extra[\"dpi\"] = self.dpi\n    return ExtractorMetadata(\n        extractor_type=ExtractorType.PADDLE,\n        extra=extra,\n    )\n</code></pre>"},{"location":"reference/extractors/#unifex.ocr.extractors.paddle_ocr.PaddleOcrExtractor.close","title":"<code>close()</code>","text":"<p>Release resources.</p> Source code in <code>unifex/ocr/extractors/paddle_ocr.py</code> <pre><code>def close(self) -&gt; None:\n    \"\"\"Release resources.\"\"\"\n    self._images.close()\n</code></pre>"},{"location":"reference/extractors/#cloud-ocr-extractors","title":"Cloud OCR Extractors","text":""},{"location":"reference/extractors/#azuredocumentintelligenceextractor","title":"AzureDocumentIntelligenceExtractor","text":"<p>Azure Document Intelligence OCR.</p>"},{"location":"reference/extractors/#unifex.ocr.extractors.azure_di.AzureDocumentIntelligenceExtractor","title":"<code>unifex.ocr.extractors.azure_di.AzureDocumentIntelligenceExtractor</code>","text":"<p>               Bases: <code>BaseExtractor</code></p> <p>Extract text from documents using Azure Document Intelligence.</p> Source code in <code>unifex/ocr/extractors/azure_di.py</code> <pre><code>class AzureDocumentIntelligenceExtractor(BaseExtractor):\n    \"\"\"Extract text from documents using Azure Document Intelligence.\"\"\"\n\n    def __init__(\n        self,\n        path: Path | str,\n        endpoint: str,\n        key: str,\n        model_id: str = \"prebuilt-read\",\n        output_unit: CoordinateUnit = CoordinateUnit.POINTS,\n    ) -&gt; None:\n        _check_azure_installed()\n        from azure.ai.documentintelligence import DocumentIntelligenceClient\n        from azure.core.credentials import AzureKeyCredential\n\n        super().__init__(path, output_unit)\n        self.endpoint = endpoint\n        self.model_id = model_id\n        self._client: DocumentIntelligenceClient = DocumentIntelligenceClient(\n            endpoint=endpoint,\n            credential=AzureKeyCredential(key),\n        )\n        self._result: Any | None = None\n        self._adapter: AzureDocumentIntelligenceAdapter | None = None\n        self._analyze_document()\n\n    def _analyze_document(self) -&gt; None:\n        \"\"\"Send document to Azure DI for analysis.\"\"\"\n        try:\n            with open(self.path, \"rb\") as f:\n                poller = self._client.begin_analyze_document(\n                    model_id=self.model_id,\n                    body=f,\n                    content_type=\"application/octet-stream\",\n                )\n                self._result = poller.result()\n                self._adapter = AzureDocumentIntelligenceAdapter(self._result, self.model_id)\n        except (OSError, ValueError) as e:\n            logger.warning(\"Failed to analyze document with Azure DI: %s\", e)\n            self._result = None\n            self._adapter = AzureDocumentIntelligenceAdapter(None, self.model_id)\n\n    def get_page_count(self) -&gt; int:\n        if self._adapter is None:\n            return 0\n        return self._adapter.page_count\n\n    def extract_page(self, page: int) -&gt; PageExtractionResult:\n        \"\"\"Extract a single page by number (0-indexed).\"\"\"\n        try:\n            if self._adapter is None:\n                raise ValueError(\"Document analysis failed\")\n\n            converted_page = self._adapter.convert_page(page)\n            # Convert from native INCHES to output_unit\n            converted_page = self._convert_page(converted_page, CoordinateUnit.INCHES)\n            return PageExtractionResult(page=converted_page, success=True)\n\n        except (IndexError, ValueError, AttributeError) as e:\n            logger.warning(\"Failed to extract page %d from Azure DI result: %s\", page, e)\n            return PageExtractionResult(\n                page=Page(page=page, width=0, height=0, texts=[]),\n                success=False,\n                error=str(e),\n            )\n\n    def get_extractor_metadata(self) -&gt; ExtractorMetadata:\n        if self._adapter is None:\n            return AzureDocumentIntelligenceAdapter(None, self.model_id).get_metadata()\n        return self._adapter.get_metadata()\n\n    def close(self) -&gt; None:\n        if self._client is not None:\n            self._client.close()\n</code></pre>"},{"location":"reference/extractors/#unifex.ocr.extractors.azure_di.AzureDocumentIntelligenceExtractor.extract_page","title":"<code>extract_page(page)</code>","text":"<p>Extract a single page by number (0-indexed).</p> Source code in <code>unifex/ocr/extractors/azure_di.py</code> <pre><code>def extract_page(self, page: int) -&gt; PageExtractionResult:\n    \"\"\"Extract a single page by number (0-indexed).\"\"\"\n    try:\n        if self._adapter is None:\n            raise ValueError(\"Document analysis failed\")\n\n        converted_page = self._adapter.convert_page(page)\n        # Convert from native INCHES to output_unit\n        converted_page = self._convert_page(converted_page, CoordinateUnit.INCHES)\n        return PageExtractionResult(page=converted_page, success=True)\n\n    except (IndexError, ValueError, AttributeError) as e:\n        logger.warning(\"Failed to extract page %d from Azure DI result: %s\", page, e)\n        return PageExtractionResult(\n            page=Page(page=page, width=0, height=0, texts=[]),\n            success=False,\n            error=str(e),\n        )\n</code></pre>"},{"location":"reference/extractors/#googledocumentaiextractor","title":"GoogleDocumentAIExtractor","text":"<p>Google Document AI OCR.</p>"},{"location":"reference/extractors/#unifex.ocr.extractors.google_docai.GoogleDocumentAIExtractor","title":"<code>unifex.ocr.extractors.google_docai.GoogleDocumentAIExtractor</code>","text":"<p>               Bases: <code>BaseExtractor</code></p> <p>Extract text from documents using Google Document AI.</p> Source code in <code>unifex/ocr/extractors/google_docai.py</code> <pre><code>class GoogleDocumentAIExtractor(BaseExtractor):\n    \"\"\"Extract text from documents using Google Document AI.\"\"\"\n\n    def __init__(\n        self,\n        path: Path | str,\n        processor_name: str,\n        credentials_path: str,\n        mime_type: str | None = None,\n        output_unit: CoordinateUnit = CoordinateUnit.POINTS,\n    ) -&gt; None:\n        \"\"\"Initialize Google Document AI extractor.\n\n        Args:\n            path: Path to the document file.\n            processor_name: Full processor resource name, e.g.,\n                'projects/{project}/locations/{location}/processors/{processor_id}'\n            credentials_path: Path to service account JSON credentials file.\n            mime_type: Optional MIME type. If not provided, will be inferred from file extension.\n            output_unit: Coordinate unit for output. Default POINTS.\n        \"\"\"\n        _check_google_docai_installed()\n        from google.cloud import documentai\n        from google.oauth2 import service_account\n\n        super().__init__(path, output_unit)\n        self.processor_name = processor_name\n        self.credentials_path = credentials_path\n        self.mime_type = mime_type or self._infer_mime_type()\n\n        # Create credentials from service account file\n        credentials = service_account.Credentials.from_service_account_file(credentials_path)\n\n        # Extract location from processor name for endpoint\n        # Format: projects/{project}/locations/{location}/processors/{processor_id}\n        location = self._extract_location_from_processor_name(processor_name)\n        opts = {\"api_endpoint\": f\"{location}-documentai.googleapis.com\"}\n\n        self._client = documentai.DocumentProcessorServiceClient(\n            credentials=credentials, client_options=opts\n        )\n        self._document: Document | None = None\n        self._adapter: GoogleDocumentAIAdapter | None = None\n        self._process_document()\n\n    def _infer_mime_type(self) -&gt; str:\n        \"\"\"Infer MIME type from file extension.\"\"\"\n        suffix = self.path.suffix.lower()\n        mime_types = {\n            \".pdf\": \"application/pdf\",\n            \".png\": \"image/png\",\n            \".jpg\": \"image/jpeg\",\n            \".jpeg\": \"image/jpeg\",\n            \".tiff\": \"image/tiff\",\n            \".tif\": \"image/tiff\",\n            \".gif\": \"image/gif\",\n            \".bmp\": \"image/bmp\",\n            \".webp\": \"image/webp\",\n        }\n        return mime_types.get(suffix, \"application/pdf\")\n\n    @staticmethod\n    def _extract_location_from_processor_name(processor_name: str) -&gt; str:\n        \"\"\"Extract location from processor resource name.\"\"\"\n        # Format: projects/{project}/locations/{location}/processors/{processor_id}\n        parts = processor_name.split(\"/\")\n        try:\n            loc_index = parts.index(\"locations\")\n            return parts[loc_index + 1]\n        except (ValueError, IndexError):\n            return \"us\"  # Default to US\n\n    def _process_document(self) -&gt; None:\n        \"\"\"Send document to Google Document AI for processing.\"\"\"\n        from google.cloud import documentai\n\n        try:\n            with open(self.path, \"rb\") as f:\n                content = f.read()\n\n            raw_document = documentai.RawDocument(\n                content=content,\n                mime_type=self.mime_type,\n            )\n\n            request = documentai.ProcessRequest(\n                name=self.processor_name,\n                raw_document=raw_document,\n            )\n\n            result = self._client.process_document(request=request)\n            self._document = result.document\n            self._adapter = GoogleDocumentAIAdapter(self._document, self.processor_name)\n\n        except (OSError, ValueError, Exception) as e:\n            logger.warning(\"Failed to process document with Google Document AI: %s\", e)\n            self._document = None\n            self._adapter = GoogleDocumentAIAdapter(None, self.processor_name)\n\n    def get_page_count(self) -&gt; int:\n        if self._adapter is None:\n            return 0\n        return self._adapter.page_count\n\n    def extract_page(self, page: int) -&gt; PageExtractionResult:\n        \"\"\"Extract a single page by number (0-indexed).\"\"\"\n        try:\n            if self._adapter is None:\n                raise ValueError(\"Document processing failed\")\n\n            converted_page = self._adapter.convert_page(page)\n            # Google DocAI outputs pixels after denormalization\n            # Use 72 DPI as standard PDF resolution for conversion\n            converted_page = self._convert_page(converted_page, CoordinateUnit.PIXELS, dpi=72.0)\n            return PageExtractionResult(page=converted_page, success=True)\n\n        except (IndexError, ValueError, AttributeError) as e:\n            logger.warning(\"Failed to extract page %d from Google Document AI result: %s\", page, e)\n            return PageExtractionResult(\n                page=Page(page=page, width=0, height=0, texts=[]),\n                success=False,\n                error=str(e),\n            )\n\n    def get_extractor_metadata(self) -&gt; ExtractorMetadata:\n        if self._adapter is None:\n            return GoogleDocumentAIAdapter(None, self.processor_name).get_metadata()\n        return self._adapter.get_metadata()\n\n    def close(self) -&gt; None:\n        if self._client is not None:\n            self._client.transport.close()\n</code></pre>"},{"location":"reference/extractors/#unifex.ocr.extractors.google_docai.GoogleDocumentAIExtractor.__init__","title":"<code>__init__(path, processor_name, credentials_path, mime_type=None, output_unit=CoordinateUnit.POINTS)</code>","text":"<p>Initialize Google Document AI extractor.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path | str</code> <p>Path to the document file.</p> required <code>processor_name</code> <code>str</code> <p>Full processor resource name, e.g., 'projects/{project}/locations/{location}/processors/{processor_id}'</p> required <code>credentials_path</code> <code>str</code> <p>Path to service account JSON credentials file.</p> required <code>mime_type</code> <code>str | None</code> <p>Optional MIME type. If not provided, will be inferred from file extension.</p> <code>None</code> <code>output_unit</code> <code>CoordinateUnit</code> <p>Coordinate unit for output. Default POINTS.</p> <code>POINTS</code> Source code in <code>unifex/ocr/extractors/google_docai.py</code> <pre><code>def __init__(\n    self,\n    path: Path | str,\n    processor_name: str,\n    credentials_path: str,\n    mime_type: str | None = None,\n    output_unit: CoordinateUnit = CoordinateUnit.POINTS,\n) -&gt; None:\n    \"\"\"Initialize Google Document AI extractor.\n\n    Args:\n        path: Path to the document file.\n        processor_name: Full processor resource name, e.g.,\n            'projects/{project}/locations/{location}/processors/{processor_id}'\n        credentials_path: Path to service account JSON credentials file.\n        mime_type: Optional MIME type. If not provided, will be inferred from file extension.\n        output_unit: Coordinate unit for output. Default POINTS.\n    \"\"\"\n    _check_google_docai_installed()\n    from google.cloud import documentai\n    from google.oauth2 import service_account\n\n    super().__init__(path, output_unit)\n    self.processor_name = processor_name\n    self.credentials_path = credentials_path\n    self.mime_type = mime_type or self._infer_mime_type()\n\n    # Create credentials from service account file\n    credentials = service_account.Credentials.from_service_account_file(credentials_path)\n\n    # Extract location from processor name for endpoint\n    # Format: projects/{project}/locations/{location}/processors/{processor_id}\n    location = self._extract_location_from_processor_name(processor_name)\n    opts = {\"api_endpoint\": f\"{location}-documentai.googleapis.com\"}\n\n    self._client = documentai.DocumentProcessorServiceClient(\n        credentials=credentials, client_options=opts\n    )\n    self._document: Document | None = None\n    self._adapter: GoogleDocumentAIAdapter | None = None\n    self._process_document()\n</code></pre>"},{"location":"reference/extractors/#unifex.ocr.extractors.google_docai.GoogleDocumentAIExtractor.extract_page","title":"<code>extract_page(page)</code>","text":"<p>Extract a single page by number (0-indexed).</p> Source code in <code>unifex/ocr/extractors/google_docai.py</code> <pre><code>def extract_page(self, page: int) -&gt; PageExtractionResult:\n    \"\"\"Extract a single page by number (0-indexed).\"\"\"\n    try:\n        if self._adapter is None:\n            raise ValueError(\"Document processing failed\")\n\n        converted_page = self._adapter.convert_page(page)\n        # Google DocAI outputs pixels after denormalization\n        # Use 72 DPI as standard PDF resolution for conversion\n        converted_page = self._convert_page(converted_page, CoordinateUnit.PIXELS, dpi=72.0)\n        return PageExtractionResult(page=converted_page, success=True)\n\n    except (IndexError, ValueError, AttributeError) as e:\n        logger.warning(\"Failed to extract page %d from Google Document AI result: %s\", page, e)\n        return PageExtractionResult(\n            page=Page(page=page, width=0, height=0, texts=[]),\n            success=False,\n            error=str(e),\n        )\n</code></pre>"},{"location":"reference/extractors/#llm-extractors","title":"LLM Extractors","text":""},{"location":"reference/extractors/#extract_structured","title":"extract_structured","text":"<p>Synchronous LLM extraction function.</p>"},{"location":"reference/extractors/#unifex.llm_factory.extract_structured","title":"<code>unifex.llm_factory.extract_structured(path, model, *, schema=None, prompt=None, pages=None, max_workers=1, executor=ExecutorType.THREAD, dpi=200, max_retries=3, temperature=0.0, credentials=None, base_url=None, headers=None, _extractor=None)</code>","text":"<pre><code>extract_structured(\n    path: Path | str,\n    model: str,\n    *,\n    schema: type[T],\n    prompt: str | None = None,\n    pages: list[int] | None = None,\n    max_workers: int = 1,\n    executor: ExecutorType = ExecutorType.THREAD,\n    dpi: int = 200,\n    max_retries: int = 3,\n    temperature: float = 0.0,\n    credentials: dict[str, str] | None = None,\n    base_url: str | None = None,\n    headers: dict[str, str] | None = None,\n    _extractor: Any = None,\n) -&gt; LLMExtractionResult[T]\n</code></pre><pre><code>extract_structured(\n    path: Path | str,\n    model: str,\n    *,\n    schema: None = None,\n    prompt: str | None = None,\n    pages: list[int] | None = None,\n    max_workers: int = 1,\n    executor: ExecutorType = ExecutorType.THREAD,\n    dpi: int = 200,\n    max_retries: int = 3,\n    temperature: float = 0.0,\n    credentials: dict[str, str] | None = None,\n    base_url: str | None = None,\n    headers: dict[str, str] | None = None,\n    _extractor: Any = None,\n) -&gt; LLMExtractionResult[dict[str, Any]]\n</code></pre> <p>Extract structured data from a document using an LLM.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path | str</code> <p>Path to document/image file.</p> required <code>model</code> <code>str</code> <p>Model identifier (e.g., \"openai/gpt-4o\", \"anthropic/claude-3-5-sonnet\").</p> required <code>schema</code> <code>type[T] | None</code> <p>Pydantic model for structured output. None for free-form dict.</p> <code>None</code> <code>prompt</code> <code>str | None</code> <p>Custom extraction prompt. Auto-generated from schema if None.</p> <code>None</code> <code>pages</code> <code>list[int] | None</code> <p>Page numbers to extract from (0-indexed). None for all pages.</p> <code>None</code> <code>max_workers</code> <code>int</code> <p>Number of parallel workers. 1 means sequential (all pages in one request).          &gt;1 means parallel (1 page per request, results merged into list).</p> <code>1</code> <code>executor</code> <code>ExecutorType</code> <p>Type of executor (THREAD or PROCESS) for parallel extraction.</p> <code>THREAD</code> <code>dpi</code> <code>int</code> <p>DPI for PDF-to-image conversion.</p> <code>200</code> <code>max_retries</code> <code>int</code> <p>Max retry attempts with validation feedback.</p> <code>3</code> <code>temperature</code> <code>float</code> <p>Sampling temperature (0.0 = deterministic).</p> <code>0.0</code> <code>credentials</code> <code>dict[str, str] | None</code> <p>Override credentials dict (otherwise uses env vars).</p> <code>None</code> <code>base_url</code> <code>str | None</code> <p>Custom API base URL for OpenAI-compatible APIs (vLLM, Ollama, etc.).</p> <code>None</code> <code>headers</code> <code>dict[str, str] | None</code> <p>Custom HTTP headers for OpenAI-compatible APIs.</p> <code>None</code> <code>_extractor</code> <code>SingleExtractor[T] | None</code> <p>Internal parameter for dependency injection (testing only).</p> <code>None</code> <p>Returns:</p> Type Description <code>LLMExtractionResult[T | dict[str, Any]]</code> <p>LLMExtractionResult containing extracted data, model info, and provider.</p> <code>LLMExtractionResult[T | dict[str, Any]]</code> <p>When max_workers &gt; 1, data is a list of per-page results.</p> Source code in <code>unifex/llm_factory.py</code> <pre><code>def extract_structured(  # noqa: PLR0913\n    path: Path | str,\n    model: str,\n    *,\n    schema: type[T] | None = None,\n    prompt: str | None = None,\n    pages: list[int] | None = None,\n    max_workers: int = 1,\n    executor: ExecutorType = ExecutorType.THREAD,\n    dpi: int = 200,\n    max_retries: int = 3,\n    temperature: float = 0.0,\n    credentials: dict[str, str] | None = None,\n    base_url: str | None = None,\n    headers: dict[str, str] | None = None,\n    _extractor: SingleExtractor[T] | None = None,\n) -&gt; LLMExtractionResult[T | dict[str, Any]]:\n    \"\"\"Extract structured data from a document using an LLM.\n\n    Args:\n        path: Path to document/image file.\n        model: Model identifier (e.g., \"openai/gpt-4o\", \"anthropic/claude-3-5-sonnet\").\n        schema: Pydantic model for structured output. None for free-form dict.\n        prompt: Custom extraction prompt. Auto-generated from schema if None.\n        pages: Page numbers to extract from (0-indexed). None for all pages.\n        max_workers: Number of parallel workers. 1 means sequential (all pages in one request).\n                     &gt;1 means parallel (1 page per request, results merged into list).\n        executor: Type of executor (THREAD or PROCESS) for parallel extraction.\n        dpi: DPI for PDF-to-image conversion.\n        max_retries: Max retry attempts with validation feedback.\n        temperature: Sampling temperature (0.0 = deterministic).\n        credentials: Override credentials dict (otherwise uses env vars).\n        base_url: Custom API base URL for OpenAI-compatible APIs (vLLM, Ollama, etc.).\n        headers: Custom HTTP headers for OpenAI-compatible APIs.\n        _extractor: Internal parameter for dependency injection (testing only).\n\n    Returns:\n        LLMExtractionResult containing extracted data, model info, and provider.\n        When max_workers &gt; 1, data is a list of per-page results.\n    \"\"\"\n    path = Path(path) if isinstance(path, str) else path\n    provider, model_name = _parse_model_string(model)\n    extractor = _extractor or _extract_single\n\n    # Single-threaded: all pages in one request\n    if max_workers &lt;= 1:\n        return extractor(\n            path,\n            model,\n            schema,\n            prompt,\n            pages,\n            dpi,\n            max_retries,\n            temperature,\n            credentials,\n            base_url,\n            headers,\n        )\n\n    # Parallel: 1 page per request\n    from unifex.base import ImageLoader\n\n    # Get all pages if not specified\n    if pages is None:\n        loader = ImageLoader(path, dpi=dpi)\n        pages = list(range(loader.page_count))\n        loader.close()\n\n    # Single page - no need for parallel\n    if len(pages) &lt;= 1:\n        return extractor(\n            path,\n            model,\n            schema,\n            prompt,\n            pages,\n            dpi,\n            max_retries,\n            temperature,\n            credentials,\n            base_url,\n            headers,\n        )\n\n    # Parallel execution\n    executor_class = ProcessPoolExecutor if executor == ExecutorType.PROCESS else ThreadPoolExecutor\n\n    results: list[LLMExtractionResult[T | dict[str, Any]] | Exception] = [None] * len(pages)  # type: ignore[list-item]\n    with executor_class(max_workers=max_workers) as pool:\n        future_to_idx = {\n            pool.submit(\n                extractor,\n                path,\n                model,\n                schema,\n                prompt,\n                [page],  # Single page per request\n                dpi,\n                max_retries,\n                temperature,\n                credentials,\n                base_url,\n                headers,\n            ): i\n            for i, page in enumerate(pages)\n        }\n        for future in as_completed(future_to_idx):\n            idx = future_to_idx[future]\n            try:\n                results[idx] = future.result()\n            except Exception as e:\n                results[idx] = e\n\n    # Merge results: collect all data into a list\n    merged_data: list[T | dict[str, Any]] = []\n    total_usage: dict[str, int] = {}\n    for i, res in enumerate(results):\n        if isinstance(res, Exception):\n            raise ValueError(f\"Extraction failed for page {pages[i]}: {res}\") from res\n        extraction_result: LLMExtractionResult[T | dict[str, Any]] = res\n        merged_data.append(extraction_result.data)\n        if extraction_result.usage:\n            for key, value in extraction_result.usage.items():\n                total_usage[key] = total_usage.get(key, 0) + value\n\n    return cast(\n        \"LLMExtractionResult[T | dict[str, Any]]\",\n        LLMExtractionResult(\n            data=merged_data,\n            model=model_name,\n            provider=provider,\n            usage=total_usage if total_usage else None,\n        ),\n    )\n</code></pre>"},{"location":"reference/extractors/#extract_structured_async","title":"extract_structured_async","text":"<p>Asynchronous LLM extraction function.</p>"},{"location":"reference/extractors/#unifex.llm_factory.extract_structured_async","title":"<code>unifex.llm_factory.extract_structured_async(path, model, *, schema=None, prompt=None, pages=None, max_workers=1, dpi=200, max_retries=3, temperature=0.0, credentials=None, base_url=None, headers=None, _extractor=None)</code>  <code>async</code>","text":"<pre><code>extract_structured_async(\n    path: Path | str,\n    model: str,\n    *,\n    schema: type[T],\n    prompt: str | None = None,\n    pages: list[int] | None = None,\n    max_workers: int = 1,\n    dpi: int = 200,\n    max_retries: int = 3,\n    temperature: float = 0.0,\n    credentials: dict[str, str] | None = None,\n    base_url: str | None = None,\n    headers: dict[str, str] | None = None,\n    _extractor: Any = None,\n) -&gt; LLMExtractionResult[T]\n</code></pre><pre><code>extract_structured_async(\n    path: Path | str,\n    model: str,\n    *,\n    schema: None = None,\n    prompt: str | None = None,\n    pages: list[int] | None = None,\n    max_workers: int = 1,\n    dpi: int = 200,\n    max_retries: int = 3,\n    temperature: float = 0.0,\n    credentials: dict[str, str] | None = None,\n    base_url: str | None = None,\n    headers: dict[str, str] | None = None,\n    _extractor: Any = None,\n) -&gt; LLMExtractionResult[dict[str, Any]]\n</code></pre> <p>Async version of extract_structured.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path | str</code> <p>Path to document/image file.</p> required <code>model</code> <code>str</code> <p>Model identifier (e.g., \"openai/gpt-4o\", \"anthropic/claude-3-5-sonnet\").</p> required <code>schema</code> <code>type[T] | None</code> <p>Pydantic model for structured output. None for free-form dict.</p> <code>None</code> <code>prompt</code> <code>str | None</code> <p>Custom extraction prompt. Auto-generated from schema if None.</p> <code>None</code> <code>pages</code> <code>list[int] | None</code> <p>Page numbers to extract from (0-indexed). None for all pages.</p> <code>None</code> <code>max_workers</code> <code>int</code> <p>Number of concurrent requests. 1 means sequential (all pages in one request).          &gt;1 means parallel (1 page per request, results merged into list).</p> <code>1</code> <code>dpi</code> <code>int</code> <p>DPI for PDF-to-image conversion.</p> <code>200</code> <code>max_retries</code> <code>int</code> <p>Max retry attempts with validation feedback.</p> <code>3</code> <code>temperature</code> <code>float</code> <p>Sampling temperature (0.0 = deterministic).</p> <code>0.0</code> <code>credentials</code> <code>dict[str, str] | None</code> <p>Override credentials dict (otherwise uses env vars).</p> <code>None</code> <code>base_url</code> <code>str | None</code> <p>Custom API base URL for OpenAI-compatible APIs (vLLM, Ollama, etc.).</p> <code>None</code> <code>headers</code> <code>dict[str, str] | None</code> <p>Custom HTTP headers for OpenAI-compatible APIs.</p> <code>None</code> <code>_extractor</code> <code>AsyncSingleExtractor[T] | None</code> <p>Internal parameter for dependency injection (testing only).</p> <code>None</code> <p>Returns:</p> Type Description <code>LLMExtractionResult[T | dict[str, Any]]</code> <p>LLMExtractionResult containing extracted data, model info, and provider.</p> <code>LLMExtractionResult[T | dict[str, Any]]</code> <p>When max_workers &gt; 1, data is a list of per-page results.</p> Source code in <code>unifex/llm_factory.py</code> <pre><code>async def extract_structured_async(  # noqa: PLR0913\n    path: Path | str,\n    model: str,\n    *,\n    schema: type[T] | None = None,\n    prompt: str | None = None,\n    pages: list[int] | None = None,\n    max_workers: int = 1,\n    dpi: int = 200,\n    max_retries: int = 3,\n    temperature: float = 0.0,\n    credentials: dict[str, str] | None = None,\n    base_url: str | None = None,\n    headers: dict[str, str] | None = None,\n    _extractor: AsyncSingleExtractor[T] | None = None,\n) -&gt; LLMExtractionResult[T | dict[str, Any]]:\n    \"\"\"Async version of extract_structured.\n\n    Args:\n        path: Path to document/image file.\n        model: Model identifier (e.g., \"openai/gpt-4o\", \"anthropic/claude-3-5-sonnet\").\n        schema: Pydantic model for structured output. None for free-form dict.\n        prompt: Custom extraction prompt. Auto-generated from schema if None.\n        pages: Page numbers to extract from (0-indexed). None for all pages.\n        max_workers: Number of concurrent requests. 1 means sequential (all pages in one request).\n                     &gt;1 means parallel (1 page per request, results merged into list).\n        dpi: DPI for PDF-to-image conversion.\n        max_retries: Max retry attempts with validation feedback.\n        temperature: Sampling temperature (0.0 = deterministic).\n        credentials: Override credentials dict (otherwise uses env vars).\n        base_url: Custom API base URL for OpenAI-compatible APIs (vLLM, Ollama, etc.).\n        headers: Custom HTTP headers for OpenAI-compatible APIs.\n        _extractor: Internal parameter for dependency injection (testing only).\n\n    Returns:\n        LLMExtractionResult containing extracted data, model info, and provider.\n        When max_workers &gt; 1, data is a list of per-page results.\n    \"\"\"\n    path = Path(path) if isinstance(path, str) else path\n    provider, model_name = _parse_model_string(model)\n    extractor = _extractor or _extract_single_async\n\n    # Single request: all pages in one request\n    if max_workers &lt;= 1:\n        return await extractor(\n            path,\n            model,\n            schema,\n            prompt,\n            pages,\n            dpi,\n            max_retries,\n            temperature,\n            credentials,\n            base_url,\n            headers,\n        )\n\n    # Parallel: 1 page per request\n    from unifex.base import ImageLoader\n\n    # Get all pages if not specified\n    if pages is None:\n        loader = ImageLoader(path, dpi=dpi)\n        pages = list(range(loader.page_count))\n        loader.close()\n\n    # Single page - no need for parallel\n    if len(pages) &lt;= 1:\n        return await extractor(\n            path,\n            model,\n            schema,\n            prompt,\n            pages,\n            dpi,\n            max_retries,\n            temperature,\n            credentials,\n            base_url,\n            headers,\n        )\n\n    # Parallel async execution with semaphore to limit concurrency\n    semaphore = asyncio.Semaphore(max_workers)\n\n    async def extract_with_limit(page: int) -&gt; LLMExtractionResult[T | dict[str, Any]]:\n        async with semaphore:\n            return await extractor(\n                path,\n                model,\n                schema,\n                prompt,\n                [page],\n                dpi,\n                max_retries,\n                temperature,\n                credentials,\n                base_url,\n                headers,\n            )\n\n    # Run all extractions concurrently (limited by semaphore)\n    tasks = [extract_with_limit(page) for page in pages]\n    results = await asyncio.gather(*tasks, return_exceptions=True)\n\n    # Merge results: collect all data into a list\n    merged_data: list[T | dict[str, Any]] = []\n    total_usage: dict[str, int] = {}\n    for i, res in enumerate(results):\n        if isinstance(res, Exception):\n            raise ValueError(f\"Extraction failed for page {pages[i]}: {res}\") from res\n        extraction_result: LLMExtractionResult[T | dict[str, Any]] = res  # type: ignore[assignment]\n        merged_data.append(extraction_result.data)\n        if extraction_result.usage:\n            for key, value in extraction_result.usage.items():\n                total_usage[key] = total_usage.get(key, 0) + value\n\n    return cast(\n        \"LLMExtractionResult[T | dict[str, Any]]\",\n        LLMExtractionResult(\n            data=merged_data,\n            model=model_name,\n            provider=provider,\n            usage=total_usage if total_usage else None,\n        ),\n    )\n</code></pre>"},{"location":"reference/models/","title":"Models Reference","text":""},{"location":"reference/models/#core-models","title":"Core Models","text":""},{"location":"reference/models/#document","title":"Document","text":"<p>The top-level container for extracted content.</p>"},{"location":"reference/models/#unifex.base.Document","title":"<code>unifex.base.Document</code>","text":"<p>               Bases: <code>BaseModel</code></p> Source code in <code>unifex/base/models.py</code> <pre><code>class Document(BaseModel):\n    path: Path\n    pages: list[Page] = Field(default_factory=list)\n    metadata: ExtractorMetadata | None = None\n\n    class Config:\n        arbitrary_types_allowed = True\n</code></pre>"},{"location":"reference/models/#page","title":"Page","text":"<p>Represents a single page with text blocks and tables.</p>"},{"location":"reference/models/#unifex.base.Page","title":"<code>unifex.base.Page</code>","text":"<p>               Bases: <code>BaseModel</code></p> Source code in <code>unifex/base/models.py</code> <pre><code>class Page(BaseModel):\n    page: int\n    width: float\n    height: float\n    texts: list[TextBlock] = Field(default_factory=list)\n    tables: list[Table] = Field(default_factory=list)\n    coordinate_info: CoordinateInfo | None = None\n</code></pre>"},{"location":"reference/models/#textblock","title":"TextBlock","text":"<p>A text element with bounding box and confidence.</p>"},{"location":"reference/models/#unifex.base.TextBlock","title":"<code>unifex.base.TextBlock</code>","text":"<p>               Bases: <code>BaseModel</code></p> Source code in <code>unifex/base/models.py</code> <pre><code>class TextBlock(BaseModel):\n    text: str\n    bbox: BBox\n    rotation: float = 0.0\n    confidence: float | None = None\n    font_info: FontInfo | None = None\n</code></pre>"},{"location":"reference/models/#bbox","title":"BBox","text":"<p>Bounding box coordinates.</p>"},{"location":"reference/models/#unifex.base.BBox","title":"<code>unifex.base.BBox</code>","text":"<p>               Bases: <code>BaseModel</code></p> Source code in <code>unifex/base/models.py</code> <pre><code>class BBox(BaseModel):\n    x0: float\n    y0: float\n    x1: float\n    y1: float\n</code></pre>"},{"location":"reference/models/#table","title":"Table","text":"<p>Extracted table with rows and cells.</p>"},{"location":"reference/models/#unifex.base.Table","title":"<code>unifex.base.Table</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>A table extracted from a document page.</p> Source code in <code>unifex/base/models.py</code> <pre><code>class Table(BaseModel):\n    \"\"\"A table extracted from a document page.\"\"\"\n\n    page: int  # Page number (0-indexed)\n    cells: list[TableCell] = Field(default_factory=list)\n    row_count: int = 0\n    col_count: int = 0\n    bbox: BBox | None = None  # Table bbox if available\n</code></pre>"},{"location":"reference/models/#tablecell","title":"TableCell","text":"<p>Individual cell within a table.</p>"},{"location":"reference/models/#unifex.base.TableCell","title":"<code>unifex.base.TableCell</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>A cell within a table.</p> Source code in <code>unifex/base/models.py</code> <pre><code>class TableCell(BaseModel):\n    \"\"\"A cell within a table.\"\"\"\n\n    text: str\n    row: int\n    col: int\n    bbox: BBox | None = None  # Cell bbox if available\n</code></pre>"},{"location":"reference/models/#result-models","title":"Result Models","text":""},{"location":"reference/models/#extractionresult","title":"ExtractionResult","text":"<p>Result of document extraction.</p>"},{"location":"reference/models/#unifex.base.ExtractionResult","title":"<code>unifex.base.ExtractionResult</code>  <code>dataclass</code>","text":"<p>Result of document extraction with all page results.</p> <p>Contains the extracted document (successful pages only) and detailed results for each requested page including any errors.</p> Source code in <code>unifex/base/base.py</code> <pre><code>@dataclass\nclass ExtractionResult:\n    \"\"\"Result of document extraction with all page results.\n\n    Contains the extracted document (successful pages only) and\n    detailed results for each requested page including any errors.\n    \"\"\"\n\n    document: Document\n    page_results: list[PageExtractionResult] = field(default_factory=list)\n\n    @property\n    def success(self) -&gt; bool:\n        \"\"\"True if all requested pages were extracted successfully.\"\"\"\n        return all(r.success for r in self.page_results)\n\n    @property\n    def failed_pages(self) -&gt; list[PageExtractionResult]:\n        \"\"\"List of failed page extraction results.\"\"\"\n        return [r for r in self.page_results if not r.success]\n\n    @property\n    def errors(self) -&gt; list[tuple[int, str]]:\n        \"\"\"List of (page_number, error_message) for failed pages.\"\"\"\n        return [(r.page.page, r.error or \"\") for r in self.page_results if not r.success]\n</code></pre>"},{"location":"reference/models/#unifex.base.ExtractionResult.success","title":"<code>success</code>  <code>property</code>","text":"<p>True if all requested pages were extracted successfully.</p>"},{"location":"reference/models/#unifex.base.ExtractionResult.failed_pages","title":"<code>failed_pages</code>  <code>property</code>","text":"<p>List of failed page extraction results.</p>"},{"location":"reference/models/#unifex.base.ExtractionResult.errors","title":"<code>errors</code>  <code>property</code>","text":"<p>List of (page_number, error_message) for failed pages.</p>"},{"location":"reference/models/#pageextractionresult","title":"PageExtractionResult","text":"<p>Result of single page extraction.</p>"},{"location":"reference/models/#unifex.base.PageExtractionResult","title":"<code>unifex.base.PageExtractionResult</code>  <code>dataclass</code>","text":"<p>Result of extracting a single page.</p> Source code in <code>unifex/base/base.py</code> <pre><code>@dataclass\nclass PageExtractionResult:\n    \"\"\"Result of extracting a single page.\"\"\"\n\n    page: Page\n    success: bool\n    error: str | None = None\n</code></pre>"},{"location":"reference/models/#metadata","title":"Metadata","text":""},{"location":"reference/models/#extractormetadata","title":"ExtractorMetadata","text":"<p>Metadata about the extractor used.</p>"},{"location":"reference/models/#unifex.base.ExtractorMetadata","title":"<code>unifex.base.ExtractorMetadata</code>","text":"<p>               Bases: <code>BaseModel</code></p> Source code in <code>unifex/base/models.py</code> <pre><code>class ExtractorMetadata(BaseModel):\n    extractor_type: ExtractorType\n    creator: str | None = None\n    producer: str | None = None\n    title: str | None = None\n    author: str | None = None\n    creation_date: str | None = None\n    modification_date: str | None = None\n    extra: dict[str, Any] = Field(default_factory=dict)\n</code></pre>"}]}